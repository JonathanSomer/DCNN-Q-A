#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{algorithm,algpseudocode}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
DCNN Q&A
\end_layout

\begin_layout Author
Kessler, Somer, Itzhak
\end_layout

\begin_layout Subsection*
Unanswered Questions:
\end_layout

\begin_layout Subsubsection*
When to use StandardScaling vs Normalization?
\end_layout

\begin_layout Subsubsection*
SOLVE HW3?
\end_layout

\begin_layout Subsubsection*
Instance Normalization - don't we lose lots of information from normalzing
 each channel - 
\begin_inset Quotes eld
\end_inset

the fire channel
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Section*
Week 1
\end_layout

\begin_layout Subsubsection*
What are the inclusion relations between: AI, deep learning, machine learning
 and represntation learning?
\end_layout

\begin_layout Standard
Deep learning 
\begin_inset Formula $\subset$
\end_inset

 represntation learning 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\subset$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
 machine learning 
\begin_inset Formula $\subset$
\end_inset

AI
\end_layout

\begin_layout Subsubsection*
What are the main problems in image classification?
\end_layout

\begin_layout Standard
Semantic gap (the computer sees only numbers in a grid), viewpoint variation,
 illumination, interclass variation, background clutter, occlusion (when
 an object is partly hidden)
\end_layout

\begin_layout Subsubsection*
Define nearest neighbor refering to training and predition.
\end_layout

\begin_layout Standard
Train - memorize all data and labels.
\end_layout

\begin_layout Standard
Predict - according to the most similar training image.
\end_layout

\begin_layout Subsubsection*
Define L1 distance for images.
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{1}(I_{1},I_{2})=\Sigma_{P}|I_{1}^{P}-I_{2}^{P}|$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $P$
\end_inset

 is pixel
\end_layout

\begin_layout Subsubsection*
Define L2 distance for images.
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{2}(I_{1},I_{2})=\sqrt{\Sigma_{P}(I_{1}^{P}-I_{2}^{P})^{2}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $P$
\end_inset

 is pixel
\end_layout

\begin_layout Subsubsection*
With 
\begin_inset Formula $n$
\end_inset

 examples what is the complexity of training and prediction?
\end_layout

\begin_layout Standard
Train 
\begin_inset Formula $O(1)$
\end_inset


\end_layout

\begin_layout Standard
Predict 
\begin_inset Formula $O(N)$
\end_inset


\end_layout

\begin_layout Subsubsection*
Why is this bad?
\end_layout

\begin_layout Standard
We want fast prediction, don't mind slow training.
\end_layout

\begin_layout Subsubsection*
Define K-nearest neighbor
\end_layout

\begin_layout Standard
Same as nearest neighbor only with majority vote from the K-nearestes images.
\end_layout

\begin_layout Subsubsection*
What are hyperparameters?
\end_layout

\begin_layout Standard
Choices about the algorithm that we set and not learned.
\end_layout

\begin_layout Subsubsection*
Why use validation dataset?
\end_layout

\begin_layout Standard
To choose hyperparameters (train for learning, test for testing).
\end_layout

\begin_layout Subsubsection*
What is cross-validation?
\end_layout

\begin_layout Standard
Split train data into folds, try each fold as validation (rest as train)
 and average the result.
\end_layout

\begin_layout Subsubsection*
Why K-nearest neighbor is never used on images?
\end_layout

\begin_layout Standard
1.
 Slow in test
\end_layout

\begin_layout Standard
2.
 Distance matrics on pixels are not informative
\end_layout

\begin_layout Section*
Week 2
\end_layout

\begin_layout Subsubsection*
What does it mean to assume i.d.d on a dataset?
\end_layout

\begin_layout Standard
Identically distributed - all of the samples are taken from same distrubtion
 D.
\end_layout

\begin_layout Standard
Independently distributed - 
\begin_inset Formula $x_{i}$
\end_inset

 ∼ D is independent of 
\begin_inset Formula $x_{j}$
\end_inset

 ∼ D
\end_layout

\begin_layout Subsubsection*
Why do we need to assume i.d.d on a dataset?
\end_layout

\begin_layout Standard
Identically distributed - to know that all of the samples are from the same
 domain.
 
\end_layout

\begin_layout Standard
Independently distributed - It is unrealistic to say that the second image
 in the training set depends on the tenth image of the training set.
\end_layout

\begin_layout Subsubsection*
What is the generalization error of learned function 
\begin_inset Formula $f$
\end_inset

, target function 
\begin_inset Formula $y$
\end_inset

 on distribution 
\begin_inset Formula $D$
\end_inset

?
\end_layout

\begin_layout Standard
\begin_inset Formula $L_{D}[f,y]=\mathbb{E}_{x\sim D}[loss(f(x),y(x))]$
\end_inset


\end_layout

\begin_layout Standard
with 1-0 loss:
\end_layout

\begin_layout Standard
\begin_inset Formula $=\mathbb{E}_{x\sim D}[Indicator(f(x)\neq y(x))]$
\end_inset


\end_layout

\begin_layout Subsubsection*
Calculate:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ‏‏gen_err.PNG

\end_inset

 
\end_layout

\begin_layout Standard
slide 35 
\begin_inset Quotes eld
\end_inset

Lecture 2 - Intro to ML
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
How does machine learning differs from optimization?
\end_layout

\begin_layout Standard
In ML we want the generalization error to be low as well as the training
 error, treating ML problem as an optimization problem would lead to overfitting.
\end_layout

\begin_layout Subsubsection*
How can we control whether an algorithm is more likely to overfit or underfit?
\end_layout

\begin_layout Standard
By altering its capacity - it's ability to fit a wide variety of functions.
\end_layout

\begin_layout Standard
Algorithms with low capacity may struggle to fit the training set.
 Algorithms with high capacity can overfit by memorizing properties of the
 training set that do not serve them well on the test set.
\end_layout

\begin_layout Subsubsection*
How can we control an algorithm capacity?
\end_layout

\begin_layout Standard
One way is to choose it's hypothesis space.
\end_layout

\begin_layout Section*
Week 6a - Neural Networks in Practice
\end_layout

\begin_layout Subsubsection*
Write down the multiclass SVM loss:
\end_layout

\begin_layout Standard
\begin_inset Formula $L\left(f\left(x_{i}\right),y_{i}\right)=\sum_{j\neq y_{i}}\max\left(0,\left(f\left(x_{i}\right)_{j}+1\right)-f\left(x_{i}\right)_{y_{i}}\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
In the multiclass SVM loss, what is the minimum achievable loss?
\end_layout

\begin_layout Standard
0
\end_layout

\begin_layout Subsubsection*
In the multiclass SVM loss, what is the maximum achievable loss?
\end_layout

\begin_layout Standard
\begin_inset Formula $+\infty$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the initial loss, when 
\begin_inset Formula $W$
\end_inset

 is set to small values, 
\begin_inset Formula $s\approx0$
\end_inset

?
\end_layout

\begin_layout Standard
\begin_inset Formula $c-1$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the elastic net regularization method?
\end_layout

\begin_layout Standard
weighted sum of 
\begin_inset Formula $L_{1}$
\end_inset

 and 
\begin_inset Formula $L_{2}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Develop the softmax classifier loss (multinomial logistic regression?):
\end_layout

\begin_layout Enumerate
Our neural network outputs the final activations, called - logits, unnormalized
 log-probabilities: 
\begin_inset Formula 
\[
s
\]

\end_inset


\end_layout

\begin_layout Enumerate
We raise them to the exponent so we have positive values 
\begin_inset Formula 
\[
e^{s}
\]

\end_inset


\end_layout

\begin_layout Enumerate
We normalize the values in order to get a distribution:
\begin_inset Formula 
\[
\hat{P}_{i}=P\left(Y=k|X=x_{i}\right)=\frac{e^{s_{k}}}{\sum_{j=1}^{k}e^{s_{j}}}
\]

\end_inset


\end_layout

\begin_layout Enumerate
Our loss is the KL divergence between this distribution and the 
\begin_inset Quotes eld
\end_inset

indicator distribution for class 
\begin_inset Formula $k$
\end_inset


\begin_inset Quotes erd
\end_inset

:
\begin_inset Formula 
\[
P_{i}=P\left(Y=c|X=x_{i}\right)=\begin{cases}
1 & c=k\\
0 & \text{else}
\end{cases}
\]

\end_inset

 The KL divergence is:
\begin_inset Formula 
\begin{align*}
KL\left(\hat{P}_{i}\|P_{i}\right) & =\sum_{c=1}^{C}P_{i}\left(c\right)\log\left(\frac{P_{i}\left(c\right)}{\hat{P}_{i}\left(c\right)}\right)\\
 & =P_{i}\left(y_{i}\right)\log\left(\frac{P_{i}\left(y_{i}\right)}{\hat{P}_{i}\left(y_{i}\right)}\right)\\
 & =1\cdot\log\left(\frac{1}{\hat{P}_{i}\left(y_{i}\right)}\right)\\
 & =-\log\left(\hat{P}_{i}\left(y_{i}\right)\right)\\
 & =-\log\left(\frac{e^{s_{y_{i}}}}{\sum_{j=1}^{k}e^{s_{j}}}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the minimal loss?
\end_layout

\begin_layout Standard
\begin_inset Formula $0$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the maximal loss?
\end_layout

\begin_layout Standard
\begin_inset Formula $\infty$
\end_inset


\end_layout

\begin_layout Subsubsection*
At initialization all scores are approximately equal, what is the loss?
\end_layout

\begin_layout Standard
\begin_inset Formula $-\log\left(\frac{e^{s_{y_{i}}}}{\sum_{j=1}^{k}e^{s_{j}}}\right)=-\log\left(\frac{1}{C}\right)=\log\left(C\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is a 
\begin_inset Quotes eld
\end_inset

gradient check
\begin_inset Quotes erd
\end_inset

?
\end_layout

\begin_layout Standard
The process of validation of an analytical gradient implementation.
 
\begin_inset Newline newline
\end_inset

The analytical method is fast and exact but implementation is error prone
 so we can test it using the numerical gradient which is very straightforward
 but slow and approximate.
\end_layout

\begin_layout Subsubsection*
State and describe 3 Old-School methods for image feature extraction:
\end_layout

\begin_layout Enumerate
Color histogram
\end_layout

\begin_layout Enumerate
Histogram of Oriented Gradients - Divide the image into 
\begin_inset Formula $8\times8$
\end_inset

 sized blocks - for each pixel, compute the gradient direction and magnitude.
 We then create a histogram of 9 
\begin_inset Quotes eld
\end_inset

buckets
\begin_inset Quotes erd
\end_inset

, corresponding to 9 angles.
 We then add the relative amount of each gradient to each bucket.
 50 will be split half and half to the 40,60 buckets.
\begin_inset Newline newline
\end_inset

We concatenate these histograms to get the description.
\end_layout

\begin_layout Enumerate
Bag of words - Take a dataset of images, extract patches from them.
 Cluster the patches.
 Encode images by computing a histogram of counts by assigning each patch
 to a cluster.
\end_layout

\begin_layout Subsubsection*
Write down a brief history of convolutional neural networks, including dates,
 researchers etc.
\end_layout

\begin_layout Standard
the study of the human brain is thousands of years old.
 With the advent of modern electronics, it was only natural to try to harness
 this thinking process.
 The first step toward artificial neural networks came in 1943 when Warren
 McCulloch, a neurophysiologist, and a young mathematician, Walter Pitts,
 wrote a paper on how neurons might work.
 They modeled a simple neural network with electrical circuits.
 Reinforcing this concept of neurons and how they work was a book written
 by Donald Hebb.
 The Organization of Behavior was written in 1949.
 It pointed out that neural pathways are strengthened each time that they
 are used.
\end_layout

\begin_layout Standard
As computers advanced into their infancy of the 1950s, it became possible
 to begin to model the rudiments of these theories concerning human thought.
 Nathanial Rochester from the IBM research laboratories led the first effort
 to simulate a neural network.
 That first attempt failed.
 But later attempts were successful.
 It was during this time that traditional computing began to flower and,
 as it did, the emphasis in computing left the neural research in the background.
\end_layout

\begin_layout Standard
Yet, throughout this time, advocates of "thinking machines" continued to
 argue their cases.
 In 1956 the Dartmouth Summer Research Project on Artificial Intelligence
 provided a boost to both artificial intelligence and neural networks.
 One of the outcomes of this process was to stimulate research in both the
 intelligent side, AI, as it is known throughout the industry, and in the
 much lower level neural processing part of the brain.
\end_layout

\begin_layout Standard
In the years following the Dartmouth Project, John von Neumann suggested
 imitating simple neuron functions by using telegraph relays or vacuum tubes.
 Also, Frank Rosenblatt, a neuro-biologist of Cornell, began work on the
 Perceptron.
 He was intrigued with the operation of the eye of a fly.
 Much of the processing which tells a fly to flee is done in its eye.
 The Perceptron, which resulted from this research, was built in hardware
 and is the oldest neural network still in use today.
 A single-layer perceptron was found to be useful in classifying a continuous-va
lued set of inputs into one of two classes.
 The perceptron computes a weighted sum of the inputs, subtracts a threshold,
 and passes one of two possible values out as the result.
 Unfortunately, the perceptron is limited and was proven as such during
 the "disillusioned years" in Marvin Minsky and Seymour Papert's 1969 book
 Perceptrons.
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Just kidding Ido and Itay.
\end_layout

\begin_layout Subsubsection*
We have a 
\begin_inset Formula $32\times32\times3$
\end_inset

 sized picture, what can we know for sure about the dimensions of any filter
 in the next layer?
\end_layout

\begin_layout Standard
\begin_inset Formula $k\times k\times3$
\end_inset

 - filters always extend the full depth of the input volume
\end_layout

\begin_layout Subsubsection*
We have a 
\begin_inset Formula $32\times32\times3$
\end_inset

 sized picture, what is the number of paramaters of a 
\begin_inset Formula $k\times k$
\end_inset

 filter?
\end_layout

\begin_layout Standard
5*5*3 + 1 (bias)
\end_layout

\begin_layout Subsubsection*
We have a 
\begin_inset Formula $7\times7$
\end_inset

 image.
 Apply a 
\begin_inset Formula $3\times3$
\end_inset

 filter, stride 1.
 What is the size of the output?
\end_layout

\begin_layout Standard
\begin_inset Formula $\left((7-3)/1\right)+1=5\rightarrow5\times5$
\end_inset


\end_layout

\begin_layout Subsubsection*
We have a 
\begin_inset Formula $7\times7$
\end_inset

 image.
 Apply a 
\begin_inset Formula $3\times3$
\end_inset

 filter, stride 2.
 What is the size of the output?
\end_layout

\begin_layout Standard
\begin_inset Formula $\left((7-3)/2\right)+1=3\rightarrow3\times3$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is a common way to end up with the same size image?
\end_layout

\begin_layout Standard
\begin_inset Formula $3\times3$
\end_inset

 conv with zero padding of 1, with stride 1.
\begin_inset Formula 
\[
(N+2-3)/1+1=N-1+1=N
\]

\end_inset


\end_layout

\begin_layout Paragraph*
We have a 
\begin_inset Formula $32\times32\times3$
\end_inset

 image, 10 
\begin_inset Formula $5\times5$
\end_inset

 filters, stride 1 pad 2.
 What is the total output size?
\end_layout

\begin_layout Standard
\begin_inset Formula $(32+2\cdot2-5)/1+1=32$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $32\times32\times10$
\end_inset


\end_layout

\begin_layout Subsubsection*
What does a 
\begin_inset Formula $1\times1$
\end_inset

 convolution do?
\end_layout

\begin_layout Standard
A simple dot product over 1 pixel, through all channels.
\end_layout

\begin_layout Paragraph*
We have a 
\begin_inset Formula $32\times32\times3$
\end_inset

 image followed by a Fully connected Layer.
 What is the receptive field of a neuron in that layer?
\end_layout

\begin_layout Standard
The entire image.
\end_layout

\begin_layout Subsubsection*
Write down the typical CNN architecture structure Regex:
\end_layout

\begin_layout Standard
\begin_inset Formula $\left[\left(\left(CONV-RELU\right)*N-POOL\right)*M-\left(FC-RELU\right)*K,SOFTMAX\right]$
\end_inset


\end_layout

\begin_layout Section*
Week 7
\end_layout

\begin_layout Subsubsection*
Define the Sigmoid Function, state its value range:
\end_layout

\begin_layout Standard
\begin_inset Formula $\frac{1}{1+e^{-x}}$
\end_inset

, value from [0,1]
\end_layout

\begin_layout Subsubsection*
State the 3 problems of the Sigmoid function:
\end_layout

\begin_layout Enumerate
At high value of input 
\begin_inset Formula $|x|$
\end_inset

 the gradient approaches 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Enumerate
Outputs only positive values (leads to the 
\begin_inset Quotes eld
\end_inset

synchronized w gradients
\begin_inset Quotes erd
\end_inset

 zig zag issue)
\end_layout

\begin_layout Enumerate
\begin_inset Formula $e^{x}$
\end_inset

 is compute expensive
\end_layout

\begin_layout Subsubsection*
Take the derivative of 
\begin_inset Formula $\sigma(x)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma(x)\left(1-\sigma(x)\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
Define the tanh Function, state its value range:
\end_layout

\begin_layout Standard
\begin_inset Formula $\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$
\end_inset

, value from [-1,1]
\end_layout

\begin_layout Subsubsection*
State an 1 advantage and 2 disadvantages of Tanh:
\end_layout

\begin_layout Standard
Advantages:
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left(-1,1\right)$
\end_inset

 range is zero centered.
\end_layout

\begin_layout Standard
Disadvantages:
\end_layout

\begin_layout Enumerate
At high value of input 
\begin_inset Formula $|x|$
\end_inset

 the gradient approaches 
\begin_inset Formula $0$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $e^{x}$
\end_inset

 is compute expensive.
\end_layout

\begin_layout Subsubsection*
Define the ReLU Function
\end_layout

\begin_layout Standard
\begin_inset Formula $max(0,x)$
\end_inset

, negative are 0, and otherwise 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
State 4 advantages of Relu:
\end_layout

\begin_layout Enumerate
Doesn't saturate in + region
\end_layout

\begin_layout Enumerate
Computationally efficient
\end_layout

\begin_layout Enumerate
Converges faster than sigmoid and tanh
\end_layout

\begin_layout Enumerate
More biologically plausible than sigmoid and tanh
\end_layout

\begin_layout Subsubsection*
State 2 dis-advantages of Relu:
\end_layout

\begin_layout Enumerate
Not zero centerd
\end_layout

\begin_layout Enumerate
\begin_inset Quotes eld
\end_inset

Dead Relu
\begin_inset Quotes erd
\end_inset

 (zero gradient for negative input)
\end_layout

\begin_layout Subsubsection*
State a solution and best practice for the Dead ReLu Problem:
\end_layout

\begin_layout Standard
Initialize ReLu units with slightly positive Bias (0.01)
\end_layout

\begin_layout Subsubsection*
Define the Leaky ReLU Function
\end_layout

\begin_layout Standard
\begin_inset Formula $max(0.01x,x)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
State 4 advantages of Leaky Relu:
\end_layout

\begin_layout Enumerate
Doesn't saturate at all
\end_layout

\begin_layout Enumerate
Computationally efficient
\end_layout

\begin_layout Enumerate
Converges faster than sigmoid and tanh
\end_layout

\begin_layout Enumerate
Does not die (the dead ReLU problem)
\end_layout

\begin_layout Subsubsection*
Define the Paramatric ReLU Function (PReLU)
\end_layout

\begin_layout Standard
\begin_inset Formula $max(\alpha x,x)$
\end_inset

 where 
\begin_inset Formula $\alpha\in[0,1)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Define the Maxout Function
\end_layout

\begin_layout Standard
\begin_inset Formula $max(w_{1}\cdot x+b_{1},w_{2}\cdot x+b_{2})$
\end_inset

, just check 2 different models
\end_layout

\begin_layout Subsubsection*
Define the ELU Function
\end_layout

\begin_layout Standard
\begin_inset Formula $ELU(x)=\begin{cases}
x & x\geq0\\
\alpha(e^{x}-1) & x<0
\end{cases}$
\end_inset


\end_layout

\begin_layout Subsubsection*
What are the 5 advantages of ELU?
\end_layout

\begin_layout Enumerate
Doesn't saturate in + region
\end_layout

\begin_layout Enumerate
Converges faster than sigmoid and tanh
\end_layout

\begin_layout Enumerate
More biologically plausible than sigmoid and tanh
\end_layout

\begin_layout Enumerate
Closer to zero mean (compared with ReLU)
\end_layout

\begin_layout Enumerate
Some robustness to noise due to negative value gradient saturation.
\end_layout

\begin_layout Subsubsection*
What are the dis-advantages of ELU?
\end_layout

\begin_layout Standard
Computationally expensive
\end_layout

\begin_layout Subsubsection*
State 2 advantages of Maxout:
\end_layout

\begin_layout Enumerate
Generalizes ReLU/Leaky ReLU
\end_layout

\begin_layout Enumerate
Linear! No death.
\end_layout

\begin_layout Subsubsection*
State a disadvantage of Maxout:
\end_layout

\begin_layout Standard
Double number of paramaters.
\end_layout

\begin_layout Subsubsection*
Best practice for activation functions:
\end_layout

\begin_layout Standard
ReLU (low learning rate)-> Leaky/ELU/Maxout -> Tanh (never sigmoid)
\end_layout

\begin_layout Subsection*
Data PreProcessing
\end_layout

\begin_layout Subsubsection*
What is the typical method for preprocessing data?
\end_layout

\begin_layout Standard
Subtract column means, divide by column std.
\end_layout

\begin_layout Subsubsection*
Which 2 methods for preprocessing images are commonly used?
\end_layout

\begin_layout Standard
Center only (now division by STD):
\end_layout

\begin_layout Enumerate
Remove mean image (per pixel mean 
\begin_inset Formula $H\times W\times C$
\end_inset

)
\end_layout

\begin_layout Enumerate
Remove mean per channel (per channel mean 
\begin_inset Formula $C$
\end_inset

)
\end_layout

\begin_layout Subsection*
Weight Initialization:
\end_layout

\begin_layout Subsubsection*
What is the problem with constant weight initialization?
\end_layout

\begin_layout Standard
All nodes treated symetrically.
\end_layout

\begin_layout Subsubsection*
What is the formula for 
\begin_inset Formula $VAR(X\cdot Y)$
\end_inset

 for independent 
\begin_inset Formula $X,Y$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma_{X}^{2}\sigma_{Y}^{2}+\sigma_{X}^{2}\mu_{Y}^{2}+\sigma_{Y}^{2}\mu_{X}^{2}$
\end_inset


\end_layout

\begin_layout Subsubsection*
10 layers, 500 neurons per each, tanh activation.
 What is the problem with initializing all layers with a 
\begin_inset Formula $0.01$
\end_inset

 standard deviation, 
\begin_inset Formula $0$
\end_inset

 mean normal distribution? (describe the corresponding experiment)
\end_layout

\begin_layout Standard
All layer mean activations go to 0, all layers std go to 0.
 The reason is that we arrive at a 
\begin_inset Formula $0$
\end_inset

 mean distribution with very low STD.
\end_layout

\begin_layout Subsubsection*
10 layers, 500 neurons per each, tanh activation.
 What is the problem with initializing all layers with a 
\begin_inset Formula $1$
\end_inset

 standard deviation, 
\begin_inset Formula $0$
\end_inset

 mean normal distribution? (describe the corresponding experiment)
\end_layout

\begin_layout Standard
All neurons are activated at 
\begin_inset Formula $\{-1,1\}$
\end_inset

 (saturated) due to large variance in the input (500ish).
\end_layout

\begin_layout Subsubsection*
Describe the 
\begin_inset Quotes eld
\end_inset

Xavier Initialization
\begin_inset Quotes erd
\end_inset

 method:
\end_layout

\begin_layout Standard
\begin_inset Formula $W=np.randn(\text{fan\_in, fan\_out})\cdot\frac{1}{\sqrt{\text{fan\_in}}}$
\end_inset

, justification - 
\begin_inset Formula $\sum_{i=1}^{\text{fan in}}w_{i}x_{i}\sim N(0,1)$
\end_inset


\end_layout

\begin_layout Subsubsection*
Why does this fail with ReLU, and in what way?
\end_layout

\begin_layout Standard
We divide by 
\begin_inset Formula $\sqrt{\text{fan in}},$
\end_inset

but due to ReLU half of the weights are 0.
 So we should divide by 
\begin_inset Formula $\frac{\sqrt{\text{fan in}}}{2}$
\end_inset


\end_layout

\begin_layout Subsubsection*
How is the above initialization called?
\end_layout

\begin_layout Standard
He
\end_layout

\begin_layout Subsection*
Batch Normalization
\end_layout

\begin_layout Subsubsection*
Describe the Batch Normalization method, before which layers do we usually
 place a BN layers?:
\end_layout

\begin_layout Standard
During training: Before the activation function, usually after FC or Convolution
al layer:
\end_layout

\begin_layout Enumerate
Compute batch mean (at layer) 
\begin_inset Formula $\mu_{B}$
\end_inset


\end_layout

\begin_layout Enumerate
Compute batch std (at layer) 
\begin_inset Formula $\sigma_{B}$
\end_inset


\end_layout

\begin_layout Enumerate
Per sample activation 
\begin_inset Formula $x_{i}$
\end_inset

 compute a normalized version of the sample's activation: 
\begin_inset Formula $\hat{x_{i}}=\frac{x_{i}-\mu_{B}}{\sigma+\epsilon}$
\end_inset


\end_layout

\begin_layout Enumerate
Scale: 
\begin_inset Formula $\hat{x_{i}}\cdot\gamma+\beta\equiv BN_{\gamma,\beta}(x_{i})$
\end_inset


\end_layout

\begin_layout Subsubsection*
4 Advantages of BN?
\end_layout

\begin_layout Enumerate
The gradient flow improve (because of the gradient's scale)
\end_layout

\begin_layout Enumerate
Allow higher learning rates (because of the gradient's scale)
\end_layout

\begin_layout Enumerate
Reduce dependency on initialization
\end_layout

\begin_layout Enumerate
Regularization: each batch is normalized reletive to itself, harder to overfit
\end_layout

\begin_layout Subsubsection*
Describe BN at test time:
\end_layout

\begin_layout Standard
Instead of normalizing to the batch, normalize reletive to an estimated
 mean and varance of the input data (which is computed during the training
 time)
\end_layout

\begin_layout Subsection*
Babysitting the learning process:
\end_layout

\begin_layout Subsubsection*
Describe the generic processes of creating and training a neural net:
\end_layout

\begin_layout Enumerate
Pre-process data
\end_layout

\begin_layout Enumerate
Choose architecture
\end_layout

\begin_layout Enumerate
See reasonable loss + loss increase after adding regularization
\end_layout

\begin_layout Enumerate
Tweak learning rate:
\end_layout

\begin_deeper
\begin_layout Enumerate
No improvement = too small
\end_layout

\begin_layout Enumerate
Explodes = too big
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection*
Hyperparamater Tuning:
\end_layout

\begin_layout Subsubsection*
What is the general principle for searching for optimal paramaters?
\end_layout

\begin_layout Standard
Start with a coarse search (find correct order of magnitude), then a more
 fine search.
\end_layout

\begin_layout Subsubsection*
Name two methods for hyperparamter searching
\end_layout

\begin_layout Standard
Grid Search, Random Search
\end_layout

\begin_layout Subsubsection*
In what setting is the Random Search particularly effective?
\end_layout

\begin_layout Standard
One important paramater, one non-important.
 Instead of checking a small number of values of the important paramater
 against all values of the non-important, we get a random spread of values
 of the important one.
\end_layout

\begin_layout Subsubsection*
Give examples of hyperparamaters:
\end_layout

\begin_layout Enumerate
Architecture
\end_layout

\begin_layout Enumerate
Learning rate + update algos etc.
\end_layout

\begin_layout Enumerate
Regularization
\end_layout

\begin_layout Subsubsection*
What does the following image indicate?
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted1.png
	width 11cm

\end_inset


\end_layout

\begin_layout Standard
Bad initialization
\end_layout

\begin_layout Subsubsection*
You see a large gap between validation and train error, what you do?
\end_layout

\begin_layout Standard
Overfitting! Increase regularization.
\end_layout

\begin_layout Subsubsection*
You see no gap between validation and train error, what you do?
\end_layout

\begin_layout Standard
Increase model capacity?
\end_layout

\begin_layout Subsubsection*
What will we never think of, as a method for validating correct learning
 rate?
\end_layout

\begin_layout Standard
See that weight updates are around 0.01 of the weight magnitude.
 (norm of current weights, norm of entire update vector)
\end_layout

\begin_layout Section*
Week 8a
\end_layout

\begin_layout Subsubsection*
How do we batch normalize images?
\end_layout

\begin_layout Standard
Per channel.
\end_layout

\begin_layout Subsubsection*
What is Layer Normalization?
\end_layout

\begin_layout Standard
Normalize each example independently using all of its features: 
\begin_inset Formula 
\begin{align*}
\gamma,\beta\in1\times D\\
\mu,\sigma\in1\times N\\
y=\gamma(x-\mu)/\sigma+\beta
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Same in train and test.
\end_layout

\begin_layout Subsubsection*
When is Layer Normalization needed, why?
\end_layout

\begin_layout Standard
RNNs.
 Learning constant 
\begin_inset Formula $\gamma,\beta$
\end_inset

 can lead to bad behavior in RNNs (explode/implode).
\end_layout

\begin_layout Subsubsection*
What is Instance Normalization?
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Layer Normalization
\begin_inset Quotes erd
\end_inset

 for images.
 Normalize each example independently, per channel using all pixels of that
 channel: 
\begin_inset Formula 
\begin{align*}
\gamma,\beta\in1\times C\\
\mu,\sigma\in N\times C\\
y=\gamma(x-\mu)/\sigma+\beta
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Same in train and test.
\end_layout

\begin_layout Subsubsection*
Draw the 3 cubes of Normalization for images:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted2.png
	width 13cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What is group norm?
\end_layout

\begin_layout Standard
Same as instance norm except we use a group of channels (arbitrarily chosen?)
\end_layout

\begin_layout Subsubsection*
What is DBN?
\end_layout

\begin_layout Standard
Decorrelated Batch Norm.
 Take the decorrelated 
\begin_inset Formula $x$
\end_inset

, remove mean, divide each feature by it's standard deviation.
 Now we have 
\begin_inset Quotes eld
\end_inset

whitened data
\begin_inset Quotes erd
\end_inset


\begin_inset Formula 
\[
\Sigma^{-\frac{1}{2}}\left(x_{i}-\mu\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
State 3 problems of Vanilla SGD?
\end_layout

\begin_layout Enumerate
There can be large changes in one direction relative to others so learning
 rate does not fit all directions equally well.
\end_layout

\begin_layout Enumerate
Presence of local minima or saddle points
\end_layout

\begin_layout Enumerate
Gradients are noisy due to use of mini-batches.
\end_layout

\begin_layout Subsubsection*
What happens in SGD if in one direction we have a large gradient and in
 another a small gradient?
\end_layout

\begin_layout Standard
Jumps in large direction, slow in small direction.
\end_layout

\begin_layout Subsubsection*
What is the condition number of a hessian matrix? <LEARN MORE ABOUT THIS?>
\end_layout

\begin_layout Standard
Ratio of largest to smallest singular value.
\end_layout

\begin_layout Subsubsection*
Write down the vanilla sgd update rule of the weights?
\end_layout

\begin_layout Standard
\begin_inset Formula $W_{t+1}=W_{t}-\alpha\nabla f(W_{t})$
\end_inset


\end_layout

\begin_layout Subsubsection*
State a SGD update rule which enables the algorithm to overcome saddle points
 and local minima (zero gradients)?
\end_layout

\begin_layout Standard
Momentum!
\begin_inset Formula 
\begin{align*}
v_{0} & =0\\
v_{t+1} & =\rho v_{t}+\nabla f(W_{t})\\
W_{t+1} & =W_{t}-\alpha v_{t+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
Give an alternative formulation to the momentum formula:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
v_{0} & =0\\
v_{t+1} & =\rho v_{t}-\alpha\nabla f(W_{t})\\
W_{t+1} & =W_{t}+v_{t+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
In the Momentum method, what is the problem with adding the gradient at
 
\begin_inset Formula $W_{t}$
\end_inset

?
\end_layout

\begin_layout Standard
We are moving, the gradient at 
\begin_inset Formula $W_{t}$
\end_inset

 might not be relevant if we will move far from it due to 
\begin_inset Formula $v_{t}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
What is the solution to the previous issue (develops second formulation
 of Momentum formula)?
\end_layout

\begin_layout Standard
Nesterov momentum.
\begin_inset Formula 
\begin{align*}
v_{0} & =0\\
v_{t+1} & =\rho v_{t}-\alpha\nabla f(W_{t}+\rho v_{t})\\
W_{t+1} & =W_{t}+v_{t+1}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
What is a common re-paramatization of the Nesterov rule?
\end_layout

\begin_layout Standard
Denote:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tilde{W}_{t}=W_{t}+\rho v_{t}
\]

\end_inset

 The update rule becomes:
\begin_inset Formula 
\[
\tilde{W}_{t+1}=\tilde{W}_{t}+v_{t+1}+\rho(v_{t+1}-v_{t})
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
How do we overcome the issue of different sized gradients in different direction
s?
\end_layout

\begin_layout Standard
AdaGrad! We sum the square of the gradients at each step, and divide each
 gradient by the square root of this sum.
 (the norm of the vector of all gradients seen thus far for this direction)
\begin_inset Newline newline
\end_inset

Algorithm:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted3.png
	width 13cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What happens for directions with large gradient?
\end_layout

\begin_layout Standard
Smaller steps.
\end_layout

\begin_layout Subsubsection*
What happens for directions with small gradient?
\end_layout

\begin_layout Standard
Large steps initially.
\end_layout

\begin_layout Subsubsection*
What happens to the step size over long time?
\end_layout

\begin_layout Standard
Goes to zero.
\end_layout

\begin_layout Subsubsection*
How do you prevent this from happening?
\end_layout

\begin_layout Standard
RMSprop - apply a decay to the sum of square gradients from AdaGrad (typically
 0.9).
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted4.png
	width 13cm

\end_inset


\end_layout

\begin_layout Subsubsection*
Why is this decay computation not exactly a weighted average?
\end_layout

\begin_layout Standard
Initial gradient is 
\begin_inset Formula $0$
\end_inset

!
\end_layout

\begin_layout Subsubsection*
How is the combination of RMSprop and Momentum called?
\end_layout

\begin_layout Standard
Adam!
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted5.png
	width 13cm

\end_inset


\end_layout

\begin_layout Subsubsection*
Explain the unbiasing term:
\end_layout

\begin_layout Standard
After unfolding we have the following weighted average (assuming first moment
 is initialized to 0):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{m_{t}}=\frac{\beta^{t-1}g_{1}+\beta^{t-2}g_{2}+....g_{t}}{\beta^{t-1}+\beta^{t-2}+...+1}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What hyperparamater do all of these methods have?
\end_layout

\begin_layout Standard
Learning Rate
\end_layout

\begin_layout Subsubsection*
Draw a graph with 4 cases for constant learning rate:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted6.png

\end_inset


\end_layout

\begin_layout Subsubsection*
State 3 Methods for learning rate variation:
\end_layout

\begin_layout Enumerate
Step: divide by half every 
\begin_inset Formula $n$
\end_inset

 epochs.
\end_layout

\begin_layout Enumerate
Exponential decay: 
\begin_inset Formula $\alpha_{t}=\alpha_{0}e^{-kt}$
\end_inset


\end_layout

\begin_layout Enumerate
1/t decay: 
\begin_inset Formula $\alpha_{t}=\frac{\alpha_{0}}{\left(1+kt\right)}$
\end_inset


\end_layout

\begin_layout Subsubsection*
Why is learning rate decay less common with Adam than with SGD + Momentum:
\end_layout

\begin_layout Standard
Adam has the learning rate adjusted per paramater according to size of the
 gradient.
\end_layout

\begin_layout Subsubsection*
What is the difference in the step taken using second order optimization?
\end_layout

\begin_layout Standard
In first order we take a small step in the direction of decrease.
 In second order optimization we take a guess at the minimum directly.
\end_layout

\begin_layout Subsubsection*
Write down the second order multi-variate taylor series:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
J\left(\theta\right)\approx J\left(\theta_{0}\right)+\left(\theta-\theta_{0}\right)^{T}\nabla J\left(\theta_{0}\right)+\frac{1}{2}\left(\theta-\theta_{0}\right)^{T}{\bf H}\left(\theta-\theta_{0}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
\begin_inset Formula $\frac{\partial x^{T}Ax}{\partial x}$
\end_inset

=?
\end_layout

\begin_layout Standard
\begin_inset Formula $\left(A+A^{T}\right)x$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the critical point, according to the above expansion:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\frac{\partial J\left(\theta\right)}{\partial\theta} & =\nabla J\left(\theta_{0}\right)+{\bf H}\left(\theta-\theta_{0}\right)=0\\
{\bf H}\left(\theta-\theta_{0}\right) & =-\nabla J\left(\theta_{0}\right)\\
\theta & =\theta_{0}-{\bf H}^{-1}\nabla J\left(\theta_{0}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
How many hyperparamaters does a second order optimization scheme have?
\end_layout

\begin_layout Standard
None!
\end_layout

\begin_layout Subsubsection*
Why can't we use this in practice?
\end_layout

\begin_layout Standard
Complexity of computing 
\begin_inset Formula ${\bf H}^{-1}$
\end_inset

 is 
\begin_inset Formula $O\left(n^{3}\right)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
What is the name of an algorithm for Solving this in 
\begin_inset Formula $O\left(n^{2}\right)$
\end_inset

 time?
\end_layout

\begin_layout Standard
BFGS or L-BFGS
\end_layout

\begin_layout Subsubsection*
In what setting is L-BFGS useful?
\end_layout

\begin_layout Standard
Full batch, deterministic (consistent 
\begin_inset Formula $f\left(x\right)$
\end_inset

 to be optimized)
\end_layout

\begin_layout Subsubsection*
How do we know how many epochs to use?
\end_layout

\begin_layout Standard
Early stopping - stop when validation error starts increasing, or train
 for a lot of epochs and keep a snapshot of best performing model.
\end_layout

\begin_layout Subsubsection*
What are model ensembles?
\end_layout

\begin_layout Standard
A method for reducing variance via averaging of many models.
\end_layout

\begin_layout Subsubsection*
How can we use model ensembles in the Deep Learning setting without training
 many different models from scratch?
\end_layout

\begin_layout Standard
Use different snapshots of the same model.
\end_layout

\begin_layout Subsubsection*
A specific model seems to just improve its performance over time.
 How can we still use snapshots while having relatively varying models?
\end_layout

\begin_layout Standard
Cyclic Learning rate.
 Such as cosine annealing - start with 
\begin_inset Formula $\alpha=\alpha_{\min}+\frac{1}{2}\left(\alpha_{\max}-\alpha_{\min}\right)\left(1+\cos\left(\pi\frac{T\mod N+1}{N}\right)\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
How can we implement snapshot model ensembles without holding many paramater
 vectors?
\end_layout

\begin_layout Standard
Polyak Averaging.
 Compute a running average of the paramaters:
\begin_inset Formula 
\[
W_{\text{test}}=0.995W_{\text{test}}+0.005W_{t}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
State 7 methods for Regularization?
\end_layout

\begin_layout Enumerate
Add weight decay term to loss: 
\begin_inset Formula $L_{2},L_{1},\text{or a weighted mix of both}$
\end_inset

 (elastic net)
\end_layout

\begin_layout Enumerate
Dropout
\end_layout

\begin_layout Enumerate
Randomness - add randomness in training, average out in testing (see next
 questions)
\end_layout

\begin_layout Enumerate
Data Augmentation
\end_layout

\begin_layout Enumerate
DropConnect
\end_layout

\begin_layout Enumerate
Fractional Max Pooling
\end_layout

\begin_layout Enumerate
Stochastic Depth
\end_layout

\begin_layout Subsubsection*
Explain Dropout:
\end_layout

\begin_layout Standard
In the forward pass set each neuron to zero with probability 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
State two interpretations to why Dropout could be useful:
\end_layout

\begin_layout Enumerate
Force redundancy of features and prevent co-adaptation
\end_layout

\begin_layout Enumerate
Train an ensemble of models, each with slightly different architecture,
 all share some paramaters.
\end_layout

\begin_layout Subsubsection*
What is the issue with using models trained with Droput in the test phase?
\end_layout

\begin_layout Standard
Droupout makes output random:
\begin_inset Formula 
\[
y=f_{W}(\underset{\text{input image}}{x},\underset{\text{random mask}}{z})
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the output we would like to approximate?
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathbb{E}_{z}\left[f_{W}(x,z)\right]=\int_{z}p\left(z\right)f_{W}(x,z)dz
\]

\end_inset


\end_layout

\begin_layout Standard
This is the randomness method 
\begin_inset Quotes eld
\end_inset

template from before 
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
Why can't we simply activate all neurons in test time?
\end_layout

\begin_layout Standard
If we have trained with only 
\begin_inset Formula $p$
\end_inset

 of the neurons in each layer activated, we will have a larger expected
 value in test time.
\end_layout

\begin_layout Subsubsection*
What are 2 possible solutions for this?
\end_layout

\begin_layout Standard
In both solutions we activate all neurons in test time.
 The solutions differ in the time in which we scale the outputs.
 Assuming a neuron is kept with probability 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Enumerate
In test time, scale all activations of each layer by 
\begin_inset Formula $p$
\end_inset

.
\end_layout

\begin_layout Enumerate
In training time, divide the activations of each layer by 
\begin_inset Formula $p$
\end_inset

.
 (testing becomes a simple feedforward)
\end_layout

\begin_layout Subsubsection*
How is the second method called?
\end_layout

\begin_layout Standard
Inverted Dropout.
\end_layout

\begin_layout Subsubsection*
State _ methods for data augmentation:
\end_layout

\begin_layout Enumerate
Flips
\end_layout

\begin_layout Enumerate
Random crops and scales
\end_layout

\begin_layout Enumerate
Color jittering - randomize contrast and brightness
\end_layout

\begin_layout Enumerate
Distortions - lenses, stretch, translation, shearing etc.
\end_layout

\begin_layout Subsubsection*
How does transfer learning differ when using large/small datasets (both
 relatively similar to the original one)?
\end_layout

\begin_layout Standard
Small - finetune only last layer.
 Large - maybe finetune a few layers
\end_layout

\begin_layout Subsubsection*
How does transfer learning differ when the target dataset is very different
 from the original one.
 Explain for small/large amount of data?
\end_layout

\begin_layout Standard
Lots of data - finetune lots of layers.
 Little data - try linear classifiers from different layers, probably can't
 finetune many layers on a huge net using little data.
\end_layout

\begin_layout Section*
Week 8b - CNN Architectures
\end_layout

\begin_layout Subsection*
Given image of input 
\begin_inset Formula $227\times227\times3$
\end_inset

, and Conv2d layer with 96 filters of size
\begin_inset Formula $11\times11$
\end_inset

 with stride 
\begin_inset Formula $4$
\end_inset

, what would be the output size:
\end_layout

\begin_layout Standard
The width and height is 
\begin_inset Formula $\left(227-11\right)/4+1=55$
\end_inset

, so 
\begin_inset Formula $55\times55\times96$
\end_inset


\end_layout

\begin_layout Subsection*
Given image of input 
\begin_inset Formula $227\times227\times3$
\end_inset

, and Conv2d layer with 96 filters of size
\begin_inset Formula $11\times11$
\end_inset

 with stride 
\begin_inset Formula $4$
\end_inset

, how many parameters are there:
\end_layout

\begin_layout Standard
\begin_inset Formula $11\cdot11\cdot3$
\end_inset

 for every filter, so 
\begin_inset Formula $11\cdot11\cdot3\cdot96=34848$
\end_inset


\end_layout

\begin_layout Subsection*
Given input 
\begin_inset Formula $55\times55\times96$
\end_inset

, what will be the output of a 
\begin_inset Formula $Max\,Pool$
\end_inset

 layer with 
\begin_inset Formula $3\times3$
\end_inset

 filter size and stride 
\begin_inset Formula $2$
\end_inset

:
\end_layout

\begin_layout Standard
The width and height of the new input will be: 
\begin_inset Formula $(55-3)/2+1=27$
\end_inset

, so 
\begin_inset Formula $27\times27\times96$
\end_inset


\end_layout

\begin_layout Subsection*
Given image of input 
\begin_inset Formula $13\times13\times256$
\end_inset

, and Conv2d layer with 96 filters of size 
\begin_inset Formula $3\times3$
\end_inset

 with stride 
\begin_inset Formula $1$
\end_inset

, and 
\begin_inset Formula $1$
\end_inset

 padding what would be the output size:
\end_layout

\begin_layout Standard
\begin_inset Formula $\left(\left(13+2\cdot1\right)-3\right)/1+1=13$
\end_inset

, 
\begin_inset Formula $13\times13\times96$
\end_inset


\end_layout

\begin_layout Subsection*
How is ZFNet different from AlexNet?
\end_layout

\begin_layout Standard
ZFNet use the same architecture of AlexNet, but keep higher resolution at
 the beginning(smaller stride at start), and use more channels at the deeper
 layers.
\end_layout

\begin_layout Subsection*
What are VGGNet building blocks?
\end_layout

\begin_layout Standard
VGGNet is builded with only 
\begin_inset Formula $3\times3$
\end_inset

 filter convolution layers, 
\begin_inset Formula $2\times2$
\end_inset

 max-pool stide 
\begin_inset Formula $2$
\end_inset

 layers, and at the end fully connected layers
\end_layout

\begin_layout Subsection*
What were the 2 main changes that VGG net presented reletive to AlexNet
 and ZFNet?
\end_layout

\begin_layout Enumerate
Very small fillter right from the start that does not change the images
 sizse (
\begin_inset Formula $\left(3,3\right)$
\end_inset

, stride 
\begin_inset Formula $1$
\end_inset

, padding 
\begin_inset Formula $1$
\end_inset

)
\end_layout

\begin_layout Enumerate
More layers (deeper net)
\end_layout

\begin_layout Subsection*
What are the benefits of smaller fillter in VGGNet, for example a 
\begin_inset Formula $3\times3$
\end_inset

 filter reletive to 
\begin_inset Formula $7\times7$
\end_inset

 filter?
\end_layout

\begin_layout Enumerate

\series bold
Deeper: 
\series default
You can stack 
\begin_inset Formula $3$
\end_inset

 Conv layer with filter 
\begin_inset Formula $3\times3$
\end_inset

 of each other to get the same receptive field of a 
\begin_inset Formula $7\times7$
\end_inset

 filter.
 This allow deeper layers = more non-linearity.
\begin_inset Newline newline
\end_inset

(Each stack of 
\begin_inset Formula $3\times3$
\end_inset

 filter enlarge the receptive field of the neuron by 
\begin_inset Formula $1$
\end_inset

 to both sides, so after 
\begin_inset Formula $3$
\end_inset

 stacks you get 
\begin_inset Formula $3\times3\rightarrow5\times5\rightarrow7\times7$
\end_inset

)
\end_layout

\begin_layout Enumerate

\series bold
less parameters
\series default

\begin_inset Newline newline
\end_inset

(Each 
\begin_inset Formula $3\times3$
\end_inset

 uses 
\begin_inset Formula $3\cdot3\cdot C$
\end_inset

 parameters, so 
\begin_inset Formula $3\cdot\left(3^{2}\cdot C\right)=27\cdot C$
\end_inset

, on the other hand 
\begin_inset Formula $7\cdot7\cdot C=49\cdot C$
\end_inset

)
\end_layout

\begin_layout Subsection*
What is the 
\begin_inset Quotes eld
\end_inset

Network within a network
\begin_inset Quotes erd
\end_inset

 feature of the inception model?
\end_layout

\begin_layout Standard
Design a good network topology and stack those onto each others.
\end_layout

\begin_layout Subsection*
What is the structure of the inception model block?
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename inception_model.png
	width 5cm

\end_inset


\end_layout

\begin_layout Subsection*
What are 
\begin_inset Formula $1\times1$
\end_inset

 Conv filter used for?
\end_layout

\begin_layout Standard
To reduce the number of channels without much parameters and without losing
 resolution
\end_layout

\begin_layout Subsection*
What do you add additinal gradient at lower layers?
\end_layout

\begin_layout Standard
You can add auxilary outputs that try to classify the images at earlier
 stages.
\end_layout

\begin_layout Subsection*
When stacking convolutional layers onto each other, what happend to the
 losses as the depth get larger?
\end_layout

\begin_layout Standard
You get higher training and test error 
\begin_inset Formula $\rightarrow$
\end_inset

You don't succeed in over-fitting, even thougth the model is more complex
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename stack_convolution_layer.png
	width 4cm

\end_inset


\end_layout

\begin_layout Subsection*
Describe the ResNet blocks:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename ResNet.png
	width 5cm

\end_inset


\end_layout

\begin_layout Standard
Essentialy 
\begin_inset Formula $F(X)+X$
\end_inset


\end_layout

\begin_layout Subsection*
What does the ResNet block try to solve?
\end_layout

\begin_layout Standard
When building deeper network the input get distorted after many layers,
 and the gradient vanish when going all the way back to the first layers.
 The addition of the input at each block keep the data from distorting too
 much, and allow the gradient to flow more easily back to the first layers.
\end_layout

\begin_layout Subsection*
State 1 technique that allow you to reduce computation cost in ResNet:
\end_layout

\begin_layout Standard
Use 
\begin_inset Quotes eld
\end_inset

bottleneck
\begin_inset Quotes erd
\end_inset

 layers:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename bottleneck_layers.png
	width 5cm

\end_inset


\end_layout

\begin_layout Standard
This avoid doing filters when both the input number of chanels and the output
 number of chanels is high, instead it reduce the dimention of the data
 first to 64 and then increase it back to 256
\end_layout

\begin_layout Subsection*
State 4 ways to improve ResNet?
\end_layout

\begin_layout Enumerate
Wide ResNet (More channels)
\end_layout

\begin_layout Enumerate
Argregated ResNet (each block contain mutiple version that are agragated
 at the end)
\end_layout

\begin_layout Enumerate
Regularization: Stochastic Depth
\end_layout

\begin_layout Enumerate
Squeeze-and-Excitation networks (SENet) - Before adding back the 
\begin_inset Formula $X$
\end_inset

, learn how much to 
\begin_inset Quotes eld
\end_inset

scale
\begin_inset Quotes erd
\end_inset

 each channel
\end_layout

\begin_layout Subsubsection*
How does a Dense Block (from dense net) look like?
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/denseblock.png
	width 3cm

\end_inset


\end_layout

\begin_layout Section*
Week 9 - Recurrent Neural Nets
\end_layout

\begin_layout Subsubsection*
What is the Recurrent Neural Net function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
h_{t} & =\text{State at time }t\\
x_{t} & =\text{Input for time }t\\
F_{W}\left(h,x\right) & =\text{Function with parameters }W\text{ that recive state and input}
\end{align*}

\end_inset


\begin_inset Formula 
\[
h_{t}=F_{W}\left(h_{t-1},x_{t}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Name 3 RNN structures 'types':
\end_layout

\begin_layout Enumerate
Many to One
\end_layout

\begin_layout Enumerate
Many to Many
\end_layout

\begin_layout Enumerate
One to Many - 
\begin_inset Quotes eld
\end_inset

generate sequence from single input
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
Give an example of 
\begin_inset Quotes eld
\end_inset

Many to One
\begin_inset Quotes erd
\end_inset

 RNN
\end_layout

\begin_layout Standard
Sequence of words -> Sentiment
\end_layout

\begin_layout Subsubsection*
Give an example of 
\begin_inset Quotes eld
\end_inset

One to Many
\begin_inset Quotes erd
\end_inset

 RNN
\end_layout

\begin_layout Standard
Image -> Sequence of words
\end_layout

\begin_layout Subsubsection*
Give an example of 
\begin_inset Quotes eld
\end_inset

Many to Many
\begin_inset Quotes erd
\end_inset

 RNN
\end_layout

\begin_layout Standard
Video -> Classification on frame level
\end_layout

\begin_layout Subsection*
Write down te equation for Vanilla RNN
\end_layout

\begin_layout Standard
\begin_inset Formula $h_{t}=tanh\left(W_{hh}h_{t-1}+W_{xh}x_{t}\right)$
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Formula $y_{t}=W_{hy}h_{t}$
\end_inset


\end_layout

\begin_layout Subsubsection*
How do you train a character level RNN on some language model, and output
 same random text from it?
\end_layout

\begin_layout Standard
Train the model such that at every step it should predict the next character
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/rnn_nlp_charlevel_example.png
	width 5cm

\end_inset


\end_layout

\begin_layout Standard
Feed forward the character it predict to generate:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/rnn_nlp_charlevel_example2.png
	width 5cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What 2 ways are there to backpropogate RNN:
\end_layout

\begin_layout Enumerate

\series bold
Backpropogate through time: 
\series default
Unfold the layer repetition as different layers, backpropogate throuth all
 of them
\end_layout

\begin_layout Enumerate

\series bold
Truncated backpropogation through time: 
\series default
Unfold the layer repetition in chunks and back propogate on only those chunks
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/truncated_bpptt.png
	width 4cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What are 2 problems 
\series bold
that Truncated
\series default
 backpropogate help solve?
\end_layout

\begin_layout Enumerate
Single gradient computation require many interation unfolding
\end_layout

\begin_layout Enumerate
Gradient vanish after many iterations
\end_layout

\begin_layout Subsubsection*
How would you build a neural network that generate text descripion of the
 image?
\end_layout

\begin_layout Standard
Encode image into a latent vector (multiple conv and pooling)
\begin_inset Newline newline
\end_inset

Import the vector as a hidden state layer to RNN and generate words from
 it
\end_layout

\begin_layout Subsubsection*
Describe how would you add an attention model to the previous example
\end_layout

\begin_layout Standard
Encode the image into latent matrix of size 
\begin_inset Formula $v=Locations\times Features$
\end_inset

.
\begin_inset Newline newline
\end_inset

At each RNN step output weights vector 
\begin_inset Formula $a=Location\times1$
\end_inset

 which represent weight per location and feed the RNN with single feature
 vector 
\begin_inset Formula $z=\sum_{i=1}^{Locations}a_{i}v_{i}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/attention_model.png
	width 7cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What is multilayer RNN?
\end_layout

\begin_layout Standard
running the input of each timestamp of a RNN as a sequence that goes through
 another RNN
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/mutilayerRNN.png
	width 4cm

\end_inset


\end_layout

\begin_layout Subsubsection*
Give one way to handle vanilla RNN gradient explosion problem:
\end_layout

\begin_layout Standard
gradient clipping
\end_layout

\begin_layout Subsubsection*
What is the structure of LSTM?
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/LSTM.png
	width 12cm

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the problem LSTM network solves and how does it do that?
\end_layout

\begin_layout Standard
Vanilla RNN gradients "vanish", because of the repetative activation function
 and matrix multipication and finite-precision numbers.
\begin_inset Newline newline
\end_inset

LSTM fix this issue by creating an easier way for the gradient to flow through
 uninterrupted, which allow the gradient an easier way not to 
\begin_inset Quotes eld
\end_inset

vanish
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename C:/home/kessi/Documents/DCNN-Q-A/LSTM_highway.png
	width 8cm

\end_inset


\end_layout

\begin_layout Section*
Week 11a - Detection and Segmentation
\end_layout

\begin_layout Subsubsection*
Define Semantic Segmentation:
\end_layout

\begin_layout Standard
Tag each pixel with the type of element inside it.
 No differentiation between objects of the same type:
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted7.png

\end_inset


\end_layout

\begin_layout Subsubsection*
State 2 techniques for semantic segmentation:
\end_layout

\begin_layout Enumerate
Sliding Window
\end_layout

\begin_layout Enumerate
Fully Convolutional
\end_layout

\begin_layout Subsubsection*
What is the problem with the sliding window method?
\end_layout

\begin_layout Standard
Inefficient.
 Not sharing features between intersecting windows.
\end_layout

\begin_layout Subsubsection*
What is the problem with the second method?
\end_layout

\begin_layout Standard
complexity of convolutions at original resolution.
\end_layout

\begin_layout Subsubsection*
Solution?
\end_layout

\begin_layout Standard
Downsampling (pooling, and strided convolutions) and then upsampling (unpooling
 and strided transpose convolution)
\end_layout

\begin_layout Subsubsection*
State 3 methods for un-Pooling:
\end_layout

\begin_layout Enumerate
Nearest Neighbor - if max was a 2, set entire region to 2.
\end_layout

\begin_layout Enumerate
Bed of Nails - if max was a 2, set top left corner to 2, all others to the
 minimal value, say 0.
\end_layout

\begin_layout Enumerate
Smart Bed of Nails - keep track of max locations during pooling and place
 the max value back in that location.
\end_layout

\begin_layout Subsubsection*
Describe the transpose convolution:
\end_layout

\begin_layout Standard
Use the input as a weight applied to the convolution filter, use strides
 to re-build the image.
\end_layout

\begin_layout Subsubsection*
Write down the 1D convolution and transpose convolution.
 Using stride 1 and stride >1:
\end_layout

\begin_layout Standard
Stride 1:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\overrightarrow{x}*\overrightarrow{a} & =X\overrightarrow{a}\\
\left(\begin{array}{ccccc}
x & y & z & 0 & 0\\
0 & x & y & z & 0\\
0 & 0 & x & y & z
\end{array}\right) & \left(\begin{array}{c}
0\\
a\\
b\\
c\\
0
\end{array}\right)=\left(\begin{array}{c}
ay+bz\\
ax+by+cz\\
bx+cy
\end{array}\right)
\end{align*}

\end_inset

Stride 1 - transpose:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\overrightarrow{x}*^{T}\overrightarrow{a} & =X^{T}\overrightarrow{a}\\
\left(\begin{array}{ccc}
x & 0 & 0\\
y & x & 0\\
z & y & x\\
0 & z & y\\
0 & 0 & z
\end{array}\right) & \left(\begin{array}{c}
a\\
b\\
c
\end{array}\right)=\left(\begin{array}{c}
ax\\
ay+bx\\
az+by+cx\\
bz+cy\\
cz
\end{array}\right)
\end{align*}

\end_inset

 Stride = 2:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\overrightarrow{x}*\overrightarrow{a} & =X\overrightarrow{a}\\
\left(\begin{array}{ccccc}
x & y & z & 0 & 0\\
0 & 0 & x & y & z
\end{array}\right) & \left(\begin{array}{c}
0\\
a\\
b\\
c\\
0
\end{array}\right)=\left(\begin{array}{c}
ay+bz\\
bx+cy
\end{array}\right)
\end{align*}

\end_inset

Stride 1 - transpose:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\overrightarrow{x}*^{T}\overrightarrow{a} & =X^{T}\overrightarrow{a}\\
\left(\begin{array}{ccc}
x & 0 & 0\\
y & 0 & 0\\
z & x & 0\\
0 & y & 0\\
0 & z & x
\end{array}\right) & \left(\begin{array}{c}
a\\
b
\end{array}\right)=\left(\begin{array}{c}
ax\\
ay\\
az+bx\\
by\\
bz
\end{array}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
Describe the 3D reconstruction setting and architecure.
\end_layout

\begin_layout Standard
From set of images to 3D map of points in space.
\begin_inset Newline newline
\end_inset

2D Downsampling (pooling, and strided convolutions), 3D convolutional LSTM,
 and then 3D upsampling (unpooling and strided transpose convolution).
\end_layout

\begin_layout Subsubsection*
Describe _ methods for 2D object detection:
\end_layout

\begin_layout Enumerate
Classification + Localization: a CNN (pretrained on imagenet usually) FC
 to classification softmax loss + FC to box 
\begin_inset Formula $(x,y,w,h)$
\end_inset

 with L2 loss.
\end_layout

\begin_layout Enumerate
Classification sliding window.
\end_layout

\begin_layout Enumerate
R-CNN
\end_layout

\begin_layout Enumerate
Fast R-CNN
\end_layout

\begin_layout Enumerate
Faster R-CNN
\end_layout

\begin_layout Subsubsection*
State the issue with the Classification + Localization method:
\end_layout

\begin_layout Standard
If we have more than one object in the image, we need a different number
 of outputs.
 BAD
\end_layout

\begin_layout Subsubsection*
State the issue with sliding window:
\end_layout

\begin_layout Standard
complexity.
\end_layout

\begin_layout Subsubsection*
State an optimization for classification window
\end_layout

\begin_layout Standard
Region proposals / Selective search.
\end_layout

\begin_layout Subsubsection*
Explain the R-CNN method:
\end_layout

\begin_layout Standard
Training:
\end_layout

\begin_layout Enumerate
Obtain a feature extractor network, which can also classify images (AlexNet
 + fine-tune for example)
\end_layout

\begin_layout Enumerate
Per image in training dataset:
\end_layout

\begin_deeper
\begin_layout Enumerate
Run ROI algorithm.
 Per ROI 
\begin_inset Formula $\sim2K$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Enumerate
Feedforward warped version through network to obtain features.
 Save in large dataset of 
\begin_inset Formula 
\begin{align*}
x & =\left(\text{feature},\text{RoI BBOX}\right)\\
y & =\left(\text{is object},\text{real BBOX}\right)
\end{align*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Train SVM to identify objects.
\end_layout

\begin_layout Enumerate
Train regression models to warp predicted bbox into true bbox
\end_layout

\begin_layout Standard
Test:
\end_layout

\begin_layout Enumerate
Run image through RoI algorithm
\end_layout

\begin_layout Enumerate
Per RoI feedforward warped version through network.
\end_layout

\begin_layout Enumerate
Predict if object using SVM.
\end_layout

\begin_layout Enumerate
If object, predict which and predict true BBOX using regression models.
\end_layout

\begin_layout Subsubsection*
Main 2 problems with R-CNN:
\end_layout

\begin_layout Standard
Slow in train and test (2K ROIs), many ad-hoc training objectives (SVM,
 regression etc)
\end_layout

\begin_layout Subsubsection*
Explain the Fast-R-CNN method:
\end_layout

\begin_layout Standard
Training:
\end_layout

\begin_layout Enumerate
Obtain a feature extractor network, which can also classify images (AlexNet
 + fine-tune for example)
\end_layout

\begin_layout Enumerate
Per image in training dataset:
\end_layout

\begin_deeper
\begin_layout Enumerate
Run ROI algorithm on image to obtain BBOX.
\end_layout

\begin_layout Enumerate
Feedforward image through first 
\begin_inset Formula $n$
\end_inset

 layers of network.
 Per RoI:
\end_layout

\begin_deeper
\begin_layout Enumerate
Project RoI onto this representation.
\end_layout

\begin_layout Enumerate
Warp RoI - divide into 
\begin_inset Formula $7\times7$
\end_inset

 grid and max pool each part.
\end_layout

\begin_layout Enumerate
Feedforward this warped RoI through FC layers to obtain features.
 Save in large dataset of 
\begin_inset Formula 
\begin{align*}
x & =\left(\text{feature},\text{RoI BBOX}\right)\\
y & =\left(\text{is object},\text{real BBOX}\right)
\end{align*}

\end_inset


\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Backprop through: Train classification w/Softmax + linear regression w/Smooth
 L1 loss
\end_layout

\begin_layout Standard
Test:
\end_layout

\begin_layout Enumerate
Run image through RoI algorithm
\end_layout

\begin_layout Enumerate
Feedforward image through first 
\begin_inset Formula $n$
\end_inset

 layers of network.
 Per RoI:
\end_layout

\begin_deeper
\begin_layout Enumerate
Project RoI onto this representation.
\end_layout

\begin_layout Enumerate
Warp RoI - divide into 
\begin_inset Formula $7\times7$
\end_inset

 grid and max pool each part.
\end_layout

\begin_layout Enumerate
Feedforward this warped RoI through FC layers to obtain features.
 Per tuple of 
\begin_inset Formula 
\begin{align*}
x & =\left(\text{feature},\text{RoI BBOX}\right)\\
y & =\left(\text{is object},\text{real BBOX}\right)
\end{align*}

\end_inset

 Predict true BBOX + presence of object.
\end_layout

\end_deeper
\begin_layout Subsubsection*
Write down the smooth 
\begin_inset Formula $L_{1}$
\end_inset

 loss function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{cases}
0.5x^{2} & |x|<1\\
|x|-0.5 & \text{else}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the difference between the Fast R-CNN and the Faster R-CNN?
\end_layout

\begin_layout Standard
Faster has an additional Region Proposal Network before the RoI pooling
 (two more losses - classification obj/not obj + bbox smooth L1, in total
 4).
\end_layout

\begin_layout Subsubsection*
State a method for instance segmentation:
\end_layout

\begin_layout Standard
Mask R-CNN.
\end_layout

\begin_layout Subsubsection*
What is YOLO/SSD?
\end_layout

\begin_layout Standard
You only look once, single shot multibox detection.
\end_layout

\begin_layout Subsubsection*
How does the method for YOLO/SSD work?
\end_layout

\begin_layout Standard
Divide image into a 
\begin_inset Formula $7\times7$
\end_inset

 grid.
 For each square: give a score per class of the 
\begin_inset Formula $C$
\end_inset

 classes and regress from each of 
\begin_inset Formula $B$
\end_inset

 base boxes - to final box: 
\begin_inset Formula $(x,y,w,h,\text{confidence})$
\end_inset


\end_layout

\begin_layout Subsubsection*
You need to design an object detection network, speed is crucial accuracy
 not so much.
 Which architecture?
\end_layout

\begin_layout Standard
SSD
\end_layout

\begin_layout Subsubsection*
You need to design an object detection network, accuracy is crucial speed
 not so much.
 Which architecture?
\end_layout

\begin_layout Standard
Faster R-CNN
\end_layout

\begin_layout Subsubsection*
Describe the 3D camera model, give names.
 Specifically, the wierd one!
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted8.png

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the target of a 3D object detection task?
\end_layout

\begin_layout Standard
\begin_inset Formula $\left(x,y,z,w,h,l,r,p,y\right)$
\end_inset

 (roll, pitch yaw)
\end_layout

\begin_layout Subsubsection*
What is the simplified 3D bbox setting?
\end_layout

\begin_layout Standard
No roll and pitch.
\end_layout

\begin_layout Subsubsection*
What is the general method for 3D object detection?
\end_layout

\begin_layout Standard
Similar structure to Faster R-CNN.
 combine 3D proposals from many views and sensors.
 regress bbox numbers.
\end_layout

\begin_layout Section*
Week 11 - generative models
\end_layout

\begin_layout Subsubsection*
What are the two types of density estimation?
\end_layout

\begin_layout Enumerate
explicit - explicitly solve for and define 
\begin_inset Formula $p_{\text{model}}\left(x\right)\sim p_{\text{data}}\left(x\right)$
\end_inset


\end_layout

\begin_layout Enumerate
implicit - can only sample from some 
\begin_inset Formula $p_{\text{model}}\left(x\right)\sim p_{\text{data}}\left(x\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
Draw the taxonomy graph of generative models
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pasted9.png
	width 13cm

\end_inset


\end_layout

\begin_layout Subsubsection*
Describe the main concept behind Fully Visible Belief Networks:
\end_layout

\begin_layout Standard
Generate an entire picture via 1D distributions:
\begin_inset Formula 
\[
\prod_{i=1}^{n}p\left(x_{i}|x_{1},....,x_{i-1}\right)
\]

\end_inset

Each 
\begin_inset Formula $p$
\end_inset

 is expressed via NN.
 Optimization via Maximum Likelihood estimation on training data.
 Softmax loss on distribution outputed by NN.
\end_layout

\begin_layout Subsubsection*
Describe the PixelRNN
\end_layout

\begin_layout Standard
Generate image starting from corner.
 Spatial LSTM.
\end_layout

\begin_layout Subsubsection*
DrawBack?
\end_layout

\begin_layout Standard
Slow.
 Must work sequentially in training.
\end_layout

\begin_layout Subsubsection*
Describe the PixelCNN
\end_layout

\begin_layout Standard
Row by row, pixel by pixel.
 Generate via CNN over context region.
\end_layout

\begin_layout Subsubsection*
Which is faster? State 2 reasons.
\end_layout

\begin_layout Standard
PixelCNN:
\end_layout

\begin_layout Enumerate
Bound yourself to a smaller context region (no entire top-left hand part
 of image).
\end_layout

\begin_layout Enumerate
Can parralelize training (but not generation)! In the LSTM version we get
 a hidden state based on all previous images.
 In the PixelCNN version we can choose any pixel and use the context from
 it's surrounding in the training image.
\end_layout

\begin_layout Subsubsection*
State 3 Pros of these two models:
\end_layout

\begin_layout Enumerate
Explicitly compute 
\begin_inset Formula $p\left(x\right)$
\end_inset

 (how exactly?)
\end_layout

\begin_layout Enumerate
Empirical likelihood of training data can serve as validation
\end_layout

\begin_layout Enumerate
Good samples (huh?)
\end_layout

\begin_layout Subsubsection*
State a con of these methods
\end_layout

\begin_layout Standard
Sequential generation of pixels is slow.
\end_layout

\begin_layout Subsubsection*
Describe how to use an Autoencoder for a supervised learning task with few
 samples:
\end_layout

\begin_layout Enumerate
Train the autoencoder.
\end_layout

\begin_layout Enumerate
Drop the decoder
\end_layout

\begin_layout Enumerate
Fine tune the encoder + FC classifier part on the few labelled examples.
\end_layout

\begin_layout Subsubsection*
Describe how to use an autoencoder for generating data:
\end_layout

\begin_layout Standard
We assume that data is generated in the following manner:
\end_layout

\begin_layout Standard
Sample 
\begin_inset Formula $z$
\end_inset

 from true prior
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p_{\theta^{*}}\left(z\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Sample 
\begin_inset Formula $x$
\end_inset

 from true conditional:
\begin_inset Formula 
\[
p_{\theta^{*}}\left(x|z\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
How do we usually represent 
\begin_inset Formula $p_{\theta^{*}}\left(z\right)$
\end_inset

, and why?
\end_layout

\begin_layout Standard
A simple distribution, say Gaussian.
 It is reasonable to assume that the latent variables are distributed such
 (cat images - size of cat in image, pose, head rotation etc.).
\end_layout

\begin_layout Subsubsection*
How can we make independent features?
\end_layout

\begin_layout Standard
Diagonal 
\begin_inset Formula $\Sigma$
\end_inset


\end_layout

\begin_layout Subsubsection*
State the function for expressing likelihood of sample 
\begin_inset Formula $x$
\end_inset

, in the latent variable setting:
\end_layout

\begin_layout Standard
\begin_inset Formula $p_{\theta}\left(x\right)=\int_{z}p_{\theta}\left(z\right)\cdot p_{\theta}\left(x|z\right)dz$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the problem with trying to compute 
\begin_inset Formula $\theta$
\end_inset

 which maximizes likelihood in this setting?
\end_layout

\begin_layout Standard
Intractable, no way we can optimize for all 
\begin_inset Formula $z$
\end_inset


\end_layout

\begin_layout Subsubsection*
The solution involves using an encoder and decoder network, state what they
 compute:
\end_layout

\begin_layout Standard
Encoder network computes traits of the distribution of 
\begin_inset Formula $z$
\end_inset

 given 
\begin_inset Formula $x$
\end_inset

.
 Density function expressed as:
\begin_inset Formula $q_{\phi}\left(z|x\right)$
\end_inset

.
 Samples:
\begin_inset Formula 
\[
z|x\sim\mathcal{N}\left(\mu_{z|x},\Sigma_{z|x}\right)
\]

\end_inset

Decoder network computes traits of the distribution of 
\begin_inset Formula $x$
\end_inset

 given 
\begin_inset Formula $z$
\end_inset

.
 Density function expressed as:
\begin_inset Formula $p_{\theta}\left(x|z\right)$
\end_inset

.
 Samples:
\begin_inset Formula 
\[
x|z\sim\mathcal{N}\left(\mu_{x|z},\Sigma_{x|z}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What is ELBO?
\end_layout

\begin_layout Standard
Evidence lower bound.
 It is a lower bound on the likelihood of our training data given paramaters
 
\begin_inset Formula $\theta,\phi$
\end_inset

 of our network.
 We optimize 
\begin_inset Formula $\theta,\phi$
\end_inset

 such that this lower bound is maximized.
\end_layout

\begin_layout Subsubsection*
State the KL divergence of two distributions 
\begin_inset Formula $P,Q$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
D_{KL}\left(P||Q\right) & =\Sigma_{x\in X}P\left(x\right)\log\left(\frac{P\left(x\right)}{Q(x)}\right)=-\Sigma_{x\in X}P\left(x\right)\log\left(\frac{Q\left(x\right)}{P(x)}\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsubsection*
Develop the ELBO expression:
\end_layout

\begin_layout Standard
For some sample 
\begin_inset Formula $x$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log\left(p_{\theta}\left(x\right)\right) & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x\right)\right)\right]
\end{align*}

\end_inset

 True for any pair of random variables which do not depend on eachother.
 Now we use bayes' to express 
\begin_inset Formula $p_{\theta}\left(x\right)$
\end_inset

 differently:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
p_{\theta}\left(x\right) & =\frac{p_{\theta}\left(x\wedge z\right)}{\frac{p_{\theta}\left(x\wedge z\right)}{p_{\theta}\left(x\right)}}\\
 & =\frac{p_{\theta}\left(z\right)\cdot p_{\theta}\left(x|z\right)}{p_{\theta}\left(z|x\right)}
\end{align*}

\end_inset

 Let's resume developing the lower bound:
\begin_inset Formula 
\begin{align*}
\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x\right)\right)\right] & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(\frac{p_{\theta}\left(z\right)\cdot p_{\theta}\left(x|z\right)}{p_{\theta}\left(z|x\right)}\right)\right]\\
 & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(\frac{p_{\theta}\left(z\right)\cdot p_{\theta}\left(x|z\right)}{p_{\theta}\left(z|x\right)}\frac{q_{\phi}\left(z|x\right)}{q_{\phi}\left(z|x\right)}\right)\right]\\
 & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x|z\right)\right)-\log\left(\frac{q_{\phi}\left(z|x\right)}{p_{\theta}\left(z\right)}\right)+\log\left(\frac{q_{\phi}\left(z|x\right)}{p_{\theta}\left(z|x\right)}\right)\right]\\
 & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x|z\right)\right)\right]-\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(\frac{q_{\phi}\left(z|x\right)}{p_{\theta}\left(z\right)}\right)\right]+\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(\frac{q_{\phi}\left(z|x\right)}{p_{\theta}\left(z|x\right)}\right)\right]\\
 & =\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x|z\right)\right)\right]-D_{KL}\left(q_{\phi}\left(z|x\right)||p_{\theta}\left(z\right)\right)+D_{KL}\left(q_{\phi}\left(z|x\right)||p_{\theta}\left(z|x\right)\right)\\
 & \geq\mathbb{E}_{z\sim q_{\phi}\left(z|x\right)}\left[\log\left(p_{\theta}\left(x|z\right)\right)\right]-D_{KL}\left(q_{\phi}\left(z|x\right)||p_{\theta}\left(z\right)\right)\\
 & :=\mathcal{L}\left(x,\theta,\phi\right)
\end{align*}

\end_inset

Last inequality because 
\begin_inset Formula $D_{KL}\geq0$
\end_inset

 always.
\end_layout

\begin_layout Subsubsection*
State the optimization objective of training a VAE using the above:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\theta^{*},\phi^{*} & =\arg\underset{\theta,\phi}{\max}\sum_{i=1}^{N}\mathcal{L}\left(x^{\left(i\right)},\theta,\phi\right)
\end{align*}

\end_inset

 This term is differentiable!
\end_layout

\begin_layout Subsubsection*
State 2 pros and 2 cons of VAEs:
\end_layout

\begin_layout Standard
Pros:
\end_layout

\begin_layout Enumerate
Principled approach to generation
\end_layout

\begin_layout Enumerate
Get a feature extractor on the way
\end_layout

\begin_layout Standard
Cons:
\end_layout

\begin_layout Enumerate
Maximize a lower bound..
\end_layout

\begin_layout Enumerate
Generally blurrier and lower quality images than GANs, which are state of
 the art.
\end_layout

\begin_layout Subsubsection*
Why are they called Variational Autoencoders?
\end_layout

\begin_layout Standard
Still don't know.
\end_layout

\begin_layout Section*
Week 14 - Domain Adaptation
\end_layout

\begin_layout Subsubsection*
What is Domain Adaptation?
\end_layout

\begin_layout Standard
A ML settings in which we have little data on the target domain.
 We are training on a source domain 
\begin_inset Formula $(D_{S},y_{S})$
\end_inset

 and testing on a target domain 
\begin_inset Formula $(D_{T}y_{T})$
\end_inset

.
\end_layout

\begin_layout Standard
examples: (source, tatget): (high quality images, low quality images), (daylight
, night time), (posed, 
\begin_inset Quotes eld
\end_inset

in the wild
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Subsubsection*
State the two cases of Domain Adaptation.
\end_layout

\begin_layout Standard
1.
 We have labeld source samples.
\end_layout

\begin_layout Standard
2.
 We have labeld source samples and unlabeled target samples.
\end_layout

\begin_layout Subsubsection*
What is the differnce between Domain Adaptation and transfer learning?
\end_layout

\begin_layout Standard
In Domain Adaptation we do not have access to 
\begin_inset Formula $y_{T}$
\end_inset

 at all, it can be anything (
\begin_inset Formula $y_{T}=y_{S}$
\end_inset

or 
\begin_inset Formula $y_{T}=-y_{S}$
\end_inset

).
\end_layout

\begin_layout Subsubsection*
What assumptions we would have to make on the relationship between the source
 and the target domains?
\end_layout

\begin_layout Standard
That the distributions 
\begin_inset Formula $D_{S},D_{T}$
\end_inset

and the functions 
\begin_inset Formula $y_{S},y_{T}$
\end_inset

 are close in some sense.
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[h,y_{T}]\leq R_{D_{S}}[h,y_{S}]+dist(D_{S},D_{T})+dist(y_{S},y_{T})$
\end_inset


\end_layout

\begin_layout Subsubsection*
Desribe to first attempt for such assumption:
\end_layout

\begin_layout Subsubsection*
What is the total variation distance?
\end_layout

\begin_layout Standard
The total variation distance: 
\begin_inset Formula $d_{TV}(D_{S},D_{T}):=2max_{A\in M}|\mathbb{P}_{D_{S}}[A]-\mathbb{P}_{D_{T}}[A]|$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\mathbb{P}_{D}[A]$
\end_inset

- the probability of 
\begin_inset Formula $x\sim D$
\end_inset

 being in A
\end_layout

\begin_layout Standard
\begin_inset Formula $M$
\end_inset

 - All possible subsets of the sample space over 
\begin_inset Formula $D_{T}$
\end_inset

and 
\begin_inset Formula $D_{S}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
What is the Theorem (Ben-David et al.
 2010)?
\end_layout

\begin_layout Standard
for any hypothesis h it holds that:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[h,y_{T}]\leq R_{D_{S}}[h,y_{S}]+d_{TV}(D_{S},D_{T})+min\{\mathbb{E}_{D_{S}}[|y_{S}(x)-y_{T}(x)|],\mathbb{E}_{D_{T}}[|y_{S}(x)-y_{T}(x)|]\}$
\end_inset


\end_layout

\begin_layout Subsubsection*
What does the theorem (Ben-David et al.
 2010) gives us?
\end_layout

\begin_layout Standard
An upper bound on the argument we would like to minimize 
\begin_inset Formula $R_{D_{T}}[h,y_{T}]$
\end_inset

 by summing the source error, the variation distance between 
\begin_inset Formula $D_{S},D_{T}$
\end_inset

and differnces in 
\begin_inset Formula $y_{S},y_{T}.$
\end_inset


\end_layout

\begin_layout Subsubsection*
State the disadvantages of the theorem (Ben-David et al.
 2010).
\end_layout

\begin_layout Standard
1.
 Impractical - the second term 
\begin_inset Formula $min\{\mathbb{E}_{D_{S}}[|y_{S}(x)-y_{T}(x)|],\mathbb{E}_{D_{T}}[|y_{S}(x)-y_{T}(x)|]\}$
\end_inset

 cannot be estimated correctly.
\end_layout

\begin_layout Standard
2.
 It's a worst case distance measure
\end_layout

\begin_layout Standard
3.
 It holds for any 
\begin_inset Formula $h$
\end_inset

, we need only a bound on members oh 
\begin_inset Formula $H$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Desribe the second attempt for an assumption on the relationship between
 the source and the target domains:
\end_layout

\begin_layout Subsubsection*
What is the 
\begin_inset Formula $C$
\end_inset

-divergence?
\end_layout

\begin_layout Standard
the 
\begin_inset Formula $C$
\end_inset

-divergence between 
\begin_inset Formula $D_{S}$
\end_inset

 and 
\begin_inset Formula $D_{T}$
\end_inset

is:
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{C}(D_{S},D_{T})=2sup_{c\in C}|\mathbb{P}_{D_{S}}[I(c)]-\mathbb{P}_{D_{T}}[I(c)]|$
\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $C=H\Delta H:=\{h\,xor\,h'|h,h'\in H\}$
\end_inset


\end_layout

\begin_layout Standard
every function 
\begin_inset Formula $c\in C$
\end_inset

 is the set of disagreement between two members of 
\begin_inset Formula $H$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $I(c)$
\end_inset

- the set of all x s.t 
\begin_inset Formula $c(x)=1$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is Theorem 2 (Ben-David et al.
 2010)?
\end_layout

\begin_layout Standard
for any hypothesis h it holds that:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[h,y_{T}]\leq R_{D_{S}}[h,y_{S}]+d_{H\Delta H}(D_{S},D_{T})+\lambda$
\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\lambda:=min_{h^{*}\in H}\{R_{D_{T}}[h^{*},y_{T}]+R_{D_{S}}[h^{*},y_{S}]\}$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the triangle inequality for classification error?
\end_layout

\begin_layout Standard
for any labeling function 
\begin_inset Formula $f_{1},f_{2},f_{3}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D}[f_{1},f_{2}]\leq R_{D}[f_{1},f_{3}]+R_{D}[f_{2},f_{3}]$
\end_inset


\end_layout

\begin_layout Subsubsection*
Proof Theorem 2 (Ben-David et al.
 2010).
\end_layout

\begin_layout Standard
We start with the triangle inequality for 
\begin_inset Formula $h,y_{t},h^{*}:$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[h,y_{T}]\leq R_{D_{T}}[h,h^{*}]+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
We'll devolpe the only RHS:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[h,h^{*}]+R_{D_{T}}[h^{*},y_{T}]=R_{D_{T}}[h,h^{*}]+R_{D_{T}}[h^{*},y_{T}]+(R_{D_{S}}[h,h^{*}]-R_{D_{S}}[h,h^{*}])$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $=R_{D_{T}}[h,h^{*}]+R_{D_{T}}[h^{*},y_{T}]+(R_{D_{S}}[h,h^{*}]-R_{D_{S}}[h,h^{*}])$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\leq R_{D_{S}}[h,h^{*}]+|R_{D_{T}}[h,h^{*}]-R_{D_{S}}[h,h^{*}]|+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
We'll observe for now only the expressions in the absolute value 
\begin_inset Formula $|R_{D_{T}}[h,h^{*}]-R_{D_{S}}[h,h^{*}]|$
\end_inset

.
\end_layout

\begin_layout Standard
Recall that by definition and expected value of bernoulli variable it holds:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D}[f_{1},f_{2}]=\mathbb{E}_{D}[I[f_{1}(x)\neq f_{2}(x)]]=\mathbb{P}_{D}[I[f_{1}(x)\neq f_{2}(x)]]$
\end_inset


\end_layout

\begin_layout Standard
Addtionly it holds that:
\end_layout

\begin_layout Standard
\begin_inset Formula $I[f_{1}(x)\neq f_{2}(x)]=[f_{1}\,xor\,f_{2}(x)=1]$
\end_inset


\end_layout

\begin_layout Standard
Now well use this on the expressions in the absolute value taking 
\begin_inset Formula $f_{1}=h,f_{2}h^{*}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $|R_{D_{T}}[h,h^{*}]-R_{D_{S}}[h,h^{*}]|=|\mathbb{P}_{D_{T}}[h\,xor\,h^{*}(x)=1]-\mathbb{P}_{D_{S}}[h\,xor\,h^{*}(x)=1]|$
\end_inset


\end_layout

\begin_layout Standard
Now we can take the supremum on all possibe 
\begin_inset Formula $h\,xor\,h^{*}=H\Delta H$
\end_inset

 as an upper bound:
\end_layout

\begin_layout Standard
\begin_inset Formula $|\mathbb{P}_{D_{T}}[h\,xor\,h^{*}(x)=1]-\mathbb{P}_{D_{S}}[h\,xor\,h^{*}(x)=1]|\leq sup_{c\in H\Delta H}|\mathbb{P}_{D_{T}}[I(c)]-\mathbb{P}_{D_{S}}[I(c)]|$
\end_inset


\end_layout

\begin_layout Standard
And this was defined eariler as:
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})=sup_{c\in H\Delta H}|\mathbb{P}_{D_{T}}[I(c)]-\mathbb{P}_{D_{S}}[I(c)]|$
\end_inset


\end_layout

\begin_layout Standard
putting in all togather in original RHS:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{S}}[h,h^{*}]+|R_{D_{T}}[h,h^{*}]-R_{D_{S}}[h,h^{*}]|+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\leq R_{D_{S}}[h,h^{*}]+d_{H\Delta H}(D_{S},D_{T})+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\leq R_{D_{S}}[h,h^{*}]+d_{H\Delta H}(D_{S},D_{T})+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
Again using the triangle inequality it holds:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{S}}[h,h^{*}]\leq R_{D_{S}}[h,y_{S}]+R_{D_{S}}[h^{*},y_{S}]$
\end_inset


\end_layout

\begin_layout Standard
so we get:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{S}}[h,h^{*}]+d_{H\Delta H}(D_{S},D_{T})+R_{D_{T}}[h^{*},y_{T}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\leq R_{D_{S}}[h,y_{S}]+d_{H\Delta H}(D_{S},D_{T})+R_{D_{T}}[h^{*},y_{T}]+R_{D_{S}}[h^{*},y_{S}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $=R_{D_{S}}[h,y_{S}]+d_{H\Delta H}(D_{S},D_{T})+\lambda$
\end_inset


\end_layout

\begin_layout Standard
Q.E.D
\end_layout

\begin_layout Subsubsection*
State the advantages of theorem2 (Ben-David et al.
 2010)
\end_layout

\begin_layout Standard
1.
 The 
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})$
\end_inset

 measure is potentially smaller.
\end_layout

\begin_layout Standard
2.
 It can be estimated using samples from 
\begin_inset Formula $D_{S},D_{T}$
\end_inset


\end_layout

\begin_layout Subsubsection*
Prove that the 
\begin_inset Formula $C$
\end_inset

-divergence 
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})$
\end_inset

 measure is no larger than total variation distance 
\begin_inset Formula $d_{TV}(D_{S},D_{T})$
\end_inset

.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})=2sup_{c\in C}|\mathbb{P}_{D_{T}}[I(c)]-\mathbb{P}_{D_{S}}[I(c)]|\leq2sup_{A\in M}|\mathbb{P}_{D_{T}}[I(A)]-\mathbb{P}_{D_{S}}[I(A)]|=d_{TV}(D_{S},D_{T})$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the maximal gap between them?
\end_layout

\begin_layout Standard
The maximal gap is 2 (
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})=0$
\end_inset

, 
\begin_inset Formula $d_{TV}(D_{S},D_{T})=2$
\end_inset

).
\end_layout

\begin_layout Subsubsection*
Desribe a scenario in which it happens
\end_layout

\begin_layout Standard
This happens in a scenario where 
\begin_inset Formula $D_{S}$
\end_inset

 and 
\begin_inset Formula $D_{T}$
\end_inset

are over disjoint sets and any discriminator 
\begin_inset Formula $c\in H\Delta H$
\end_inset

 cannot distinguish between them.
\end_layout

\begin_layout Standard
\begin_inset Formula $D_{S}=\{x_{1},x_{2},x_{3}\}$
\end_inset

 
\begin_inset Formula $D_{T}=\{y_{1},y_{2},y_{3}\}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $d_{TV}(D_{S},D_{T})=2sup_{A\in M}|\mathbb{P}_{D_{T}}[I(A)]-\mathbb{P}_{D_{S}}[I(A)]|=2\cdot(1-0)=2$
\end_inset


\end_layout

\begin_layout Standard
for 
\begin_inset Formula $A=\{x_{1},x_{2},x_{3}\}$
\end_inset

.
\end_layout

\begin_layout Standard
And since any discriminator 
\begin_inset Formula $c\in H\Delta H$
\end_inset

 cannot distinguish between them it holds:
\end_layout

\begin_layout Standard
\begin_inset Formula $|I(c)\cap\{x_{1},x_{2},x_{3}\}|=|I(c)\cap\{y_{1},y_{2},y_{3}\}|$
\end_inset


\end_layout

\begin_layout Standard
So assuming 
\begin_inset Formula $D_{S}$
\end_inset

 and 
\begin_inset Formula $D_{T}$
\end_inset

 are uniform distributions we have for all 
\begin_inset Formula $c\in C$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathbb{P}_{D_{S}}[I(c)]=\frac{|I(c)\cap\{x_{1},x_{2},x_{3}\}|}{3}=\frac{|I(c)\cap\{y_{1},y_{2},y_{3}\}|}{3}=\mathbb{P}_{D_{T}}[I(c)]$
\end_inset


\end_layout

\begin_layout Standard
so
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})=2sup_{c\in C}|\mathbb{P}_{D_{T}}[I(c)]-\mathbb{P}_{D_{S}}[I(c)]|=0$
\end_inset


\end_layout

\begin_layout Subsubsection*
How can the 
\begin_inset Formula $C$
\end_inset

-divergence be estimated?
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{H\Delta H}(D_{S},D_{T})\approx d_{H\Delta H}(S_{1},S_{2})$
\end_inset


\end_layout

\begin_layout Standard
for two sets of samples 
\begin_inset Formula $S_{1}\sim D_{S}^{m}$
\end_inset

 and 
\begin_inset Formula $S_{2}\sim D_{T}^{m}$
\end_inset

 with large enough 
\begin_inset Formula $m$
\end_inset

 and depnding on 
\begin_inset Formula $H$
\end_inset

's 
\begin_inset Formula $VC$
\end_inset

 dimension.
\end_layout

\begin_layout Subsubsection*
What is the Lemma for the 
\begin_inset Formula $C$
\end_inset

-divergence estimation?
\end_layout

\begin_layout Standard
For a symmetric hypothesis class 
\begin_inset Formula $C$
\end_inset

 (one where for every 
\begin_inset Formula $c∈C$
\end_inset

, the inverse hypothesis 
\begin_inset Formula $1−c$
\end_inset

 is also in 
\begin_inset Formula $C$
\end_inset

) and samples 
\begin_inset Formula $S_{1},S_{2}$
\end_inset

 of size 
\begin_inset Formula $m$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{C}(S_{1},S_{2})=2(1-min_{c\in C}[\frac{1}{m}\Sigma_{x\in S_{1}}I[c(x)=0]+\frac{1}{m}\Sigma_{x\in S_{2}}I[c(x)=1]])$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the procedure for computing the C-divergence with this Lemma?
\end_layout

\begin_layout Standard
We find a function in C that has minimum error for the binary classification
 problem of distinguishing source from target instances.
 meaning finding 
\begin_inset Formula $c$
\end_inset

 that minimize:
\end_layout

\begin_layout Standard
\begin_inset Formula $min_{c\in C}[\frac{1}{m}\Sigma_{x\in S_{1}}I[c(x)=0]+\frac{1}{m}\Sigma_{x\in S_{2}}I[c(x)=1]]$
\end_inset


\end_layout

\begin_layout Subsubsection*
Reminds you of something?
\end_layout

\begin_layout Standard
GAN
\end_layout

\begin_layout Standard
But this is not the “full GAN“ yet, it's just the discriminator.
\end_layout

\begin_layout Standard
\begin_inset Formula $max_{D}[\frac{1}{m}\Sigma_{x\in S_{1}}log(D(x))+\frac{1}{m}\Sigma_{x\in S_{2}}log(1-D(x))]$
\end_inset


\end_layout

\begin_layout Subsubsection*
What assumption did we make on the two domains that we can maybe drop?
\end_layout

\begin_layout Standard
That the two domains are close to each other.
\end_layout

\begin_layout Subsubsection*
What can we use to drop that assumption?
\end_layout

\begin_layout Standard
Use unlabeled samples from the target domain to assume 
\begin_inset Formula $D_{S}$
\end_inset

 and 
\begin_inset Formula $D_{T}$
\end_inset

 not close by distance, but share “common characteristics“.
\end_layout

\begin_layout Subsubsection*
What can we assume to say they common characteristics?
\end_layout

\begin_layout Standard
Namly assume that there exists a function 
\begin_inset Formula $f$
\end_inset

 that maps 
\begin_inset Formula $D_{S}$
\end_inset

 and 
\begin_inset Formula $D_{T}$
\end_inset

 to a features space in which they behave similarly:
\end_layout

\begin_layout Standard
\begin_inset Formula $f\circ D_{S}\approx f\circ D_{T}$
\end_inset


\end_layout

\begin_layout Standard
For instance, for the daylight and sunset domains (dolphins), 
\begin_inset Formula $f(x)$
\end_inset

 can take an image and keep all of its features except the brightness.
\end_layout

\begin_layout Subsubsection*
How would the learned classifier 
\begin_inset Formula $h$
\end_inset

 would like?
\end_layout

\begin_layout Standard
\begin_inset Formula $h=g\circ f$
\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $f$
\end_inset

 is representation - the first layers of a neural network.
 
\end_layout

\begin_layout Standard
And 
\begin_inset Formula $g$
\end_inset

 is classification - - the last few layers of the neural network.
\end_layout

\begin_layout Subsubsection*
What is Theorem 3 (Ben-David et al.
 2010)?
\end_layout

\begin_layout Standard
for any 
\begin_inset Formula $g\in G$
\end_inset

 and 
\begin_inset Formula $f\in F$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{D_{T}}[\text{\ensuremath{g\circ f}},y_{T}]\leq R_{D_{S}}[g\circ f,y_{S}]+d_{G\Delta G}(f\circ D_{S},f\circ D_{T})+\lambda_{f}$
\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\lambda_{f}=min_{g\in G}\{R_{D_{S}}[g\circ f,y_{S}]+R_{D_{T}}[\text{\ensuremath{g\circ f}},y_{T}]\}$
\end_inset


\end_layout

\begin_layout Subsubsection*
What can we say when comparing the third 
\begin_inset Formula $\lambda$
\end_inset

 term in theorm2 and theorm3?
\end_layout

\begin_layout Standard
We assume in both cases that it's small, but in theorm3 the assumption is
 more restrictive, since we assume that the learned representation f is
 “good“.
\end_layout

\begin_layout Subsubsection*
What is the objective function for an algorithm for domain adaptation?
\end_layout

\begin_layout Standard
Minimizing 
\begin_inset Formula $R_{D_{S}}[g\circ f,y_{S}]+d_{G\Delta G}(f\circ D_{S},f\circ D_{T})$
\end_inset

.
\end_layout

\begin_layout Standard
formally, for unlabed target data 
\begin_inset Formula $\{x_{i}\}_{i=1}^{m}$
\end_inset

 and labeled source data 
\begin_inset Formula $\{(\hat{x_{i}},y_{S}(\hat{x_{i}}))\}_{i=1}^{m}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $min_{f\in F,g\in G}\frac{1}{m}\Sigma_{i=1}^{m}I[g\circ f(\hat{x_{i}})=y_{S}(\hat{x_{i})}]$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $+2(1-min_{c\in G\Delta G}[\frac{1}{m}\Sigma_{i=1}^{m}I[c(f(\hat{x_{i}}))=0]+\frac{1}{m}\Sigma_{i=1}^{m}I[c(f(x))=1]])$
\end_inset


\end_layout

\begin_layout Subsubsection*
How can we make our objective both generic and differentiable?
\end_layout

\begin_layout Standard
1.
 Break the objective into two separate losses.
\end_layout

\begin_layout Standard
2.
 Replace 
\begin_inset Formula $G∆G$
\end_inset

 with a generic set of discriminators C that return a value in [0, 1].
\end_layout

\begin_layout Standard
3.
 Replace the loss with the CE loss
\end_layout

\begin_layout Subsubsection*
Rewrite our objective in the generic and differentiable form
\end_layout

\begin_layout Standard
Source training error:
\end_layout

\begin_layout Standard
\begin_inset Formula $min_{f\in F,g\in G}\frac{1}{m}\Sigma_{i=1}^{m}loss(g\circ f(\hat{x_{i}}),y_{S}(\hat{x_{i})})$
\end_inset


\end_layout

\begin_layout Standard
Domain confusion:
\end_layout

\begin_layout Standard
\begin_inset Formula $max_{f\in F}min_{c\in C}[\frac{1}{m}\Sigma_{i=1}^{m}loss(c(f(\hat{x_{i}})),0)+\frac{1}{m}\Sigma_{i=1}^{m}loss(c(f(x))=1)]$
\end_inset

 
\end_layout

\begin_layout Subsubsection*
The second term reminds you of something?
\end_layout

\begin_layout Standard
This is a GAN in the latent space.
\end_layout

\begin_layout Subsubsection*
How can we optimize the objective?
\end_layout

\begin_layout Standard
Apply Backpropagation in 3 neural network, one for each function to be optimize:
 
\begin_inset Formula $f,g,c$
\end_inset

.
 we'll denote each network parameters 
\begin_inset Formula $\theta_{f},\theta_{g},\theta_{c}$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
What is the gradient step for 
\begin_inset Formula $\theta_{g}$
\end_inset

?
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\theta_{g}\leftarrow\theta_{g}-\mu_{1}\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{g}}loss(g\circ f(\hat{x_{i}}),y_{S}(\hat{x_{i}}))}{\theta_{g}}$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the gradient step for 
\begin_inset Formula $\theta_{c}$
\end_inset

?
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\theta_{c}\leftarrow\theta_{c}-\mu_{2}[\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(\hat{x_{i}}),0)}{\theta_{c}}+\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(x_{i}),1)}{\theta_{c}}]$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the gradient step for 
\begin_inset Formula $\theta_{f}$
\end_inset

?
\end_layout

\begin_layout Standard
It has two steps.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\theta_{f}\leftarrow\theta_{f}-\mu_{3}\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{f}}loss(g\circ f(\hat{x_{i}}),y_{S}(\hat{x_{i}}))}{\theta_{f}}$
\end_inset


\end_layout

\begin_layout Standard
and:
\end_layout

\begin_layout Standard
\begin_inset Formula $\theta_{f}\leftarrow\theta_{f}\boldsymbol{+}\mu_{4}[\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(\hat{x_{i}}),0)}{\theta_{c}}+\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(x_{i}),1)}{\theta_{c}}]$
\end_inset


\end_layout

\begin_layout Subsubsection*
What is the problem with the relationship between 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $c$
\end_inset

 in the current optimization method?
\end_layout

\begin_layout Standard
\begin_inset Formula $f$
\end_inset

 can fool 
\begin_inset Formula $c$
\end_inset

 
\begin_inset Quotes eld
\end_inset

too much
\begin_inset Quotes erd
\end_inset

 and overkill 
\begin_inset Formula $c$
\end_inset

 by making 
\begin_inset Formula $c$
\end_inset

 predict 0 for all 
\begin_inset Formula $f(x_{i})$
\end_inset

 and 1 for every 
\begin_inset Formula $f(\hat{x_{i}})$
\end_inset


\end_layout

\begin_layout Subsubsection*
What can 
\begin_inset Formula $c$
\end_inset

 do in such a case in the currect optimization method?
\end_layout

\begin_layout Standard
Flip its prediction.
\end_layout

\begin_layout Subsubsection*
What can be done to avoid this problem?
\end_layout

\begin_layout Standard
change the optimization of 
\begin_inset Formula $f$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $\theta_{f}\leftarrow\theta_{f}\boldsymbol{-}\mu_{4}[\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(\hat{x_{i}}),\boldsymbol{1})}{\theta_{c}}+\frac{1}{m}\Sigma_{i=1}^{m}\frac{\nabla_{\theta_{c}}loss(c(f(x_{i}),\boldsymbol{1})}{\theta_{c}}]$
\end_inset


\end_layout

\begin_layout Standard
Note: the second part is also unnecessary.
\end_layout

\begin_layout Section*
Variational Autoencoders - Last Lecture
\end_layout

\begin_layout Subsubsection*
Write down 
\begin_inset Formula $P\left(x\right)$
\end_inset

 using the law of total probability, given latent variable 
\begin_inset Formula $z$
\end_inset

, paramaterized by 
\begin_inset Formula $\theta$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p\left(x\right)=\int_{z}P\left(x|z,\theta\right)p\left(z\right)dz
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What do we choose 
\begin_inset Formula $P\left(X|z,\theta\right)$
\end_inset

 to be in VAEs?
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathcal{N}\left(f\left(z,\theta\right),\sigma^{2}I\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
Why?
\end_layout

\begin_layout Enumerate
The log likelihood of 
\begin_inset Formula $X$
\end_inset

 given 
\begin_inset Formula $z$
\end_inset

 becomes proportional to the euclidian distance between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $f\left(z,\theta\right)$
\end_inset

.
\end_layout

\begin_layout Enumerate
The likelihood of 
\begin_inset Formula $X$
\end_inset

 is differential w.r.t.
 
\begin_inset Formula $\theta$
\end_inset

 so can perform gradient descent.
\end_layout

\begin_layout Subsubsection*
What is the justification for always using 
\begin_inset Formula $z\sim\mathcal{N}\left(0,\sigma^{2}I\right)$
\end_inset

 for some hyperparameter 
\begin_inset Formula $\sigma$
\end_inset

?
\end_layout

\begin_layout Standard
We can assume that in it's first layers, the network will learn a mapping
 from this noise to the 
\begin_inset Quotes eld
\end_inset

true
\begin_inset Quotes erd
\end_inset

 latent variables, and from there compute the image.
\end_layout

\begin_layout Subsubsection*
Write down an approximation for 
\begin_inset Formula $p\left(x\right)=\int_{z}P\left(x|z,\theta\right)p\left(z\right)dz$
\end_inset

 ?
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
p\left(x\right)\approx\frac{1}{n}\sum_{i=1}^{n}P\left(x|z_{i}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
What is the problem with this?
\end_layout

\begin_layout Standard
Assuming we choose a small 
\begin_inset Formula $\sigma$
\end_inset

 (and we generally do, recall the 3 different 2s example), it is very rare
 to sample a 
\begin_inset Formula $z$
\end_inset

 which leads to 
\begin_inset Formula $f\left(z,\theta\right)$
\end_inset

 close to 
\begin_inset Formula $X$
\end_inset

 so we will likely have a sum of zeros.
\end_layout

\begin_layout Subsubsection*
How does the VAE method overcome this challenge?
\end_layout

\begin_layout Standard
We don't compute 
\begin_inset Formula $p\left(x\right)$
\end_inset

 through 
\begin_inset Formula $\mathbb{E}_{z\sim P}\left[p\left(x|z\right)\right]$
\end_inset

 which is hard, but compute 
\begin_inset Formula $\log p\left(x\right)$
\end_inset

 through 
\begin_inset Formula $\mathbb{E}_{z\sim Q\left(z|X\right)}\left[\log\left(p\left(x|z\right)\right)\right]$
\end_inset

 (which is easier due to the more likely presence of 
\begin_inset Formula $z$
\end_inset

 which can lead to 
\begin_inset Formula $X$
\end_inset

) along with a correction, based on the distance between 
\begin_inset Formula $Q\left(X|z\right)$
\end_inset

 and 
\begin_inset Formula $P\left(z\right)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Write down the ELBO:
\end_layout

\begin_layout Standard
Start with the equality:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log\left(p\left(X\right)\right)-KL\left(Q\left(z|X\right)||P\left(z|X\right)\right)=\mathbb{E}_{z\sim Q\left(z|X\right)}\left[\log\left(P\left(X|z\right)\right)\right]-KL\left(Q\left(z|X\right)||P\left(z\right)\right)
\]

\end_inset

 Now the ELBO:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\log\left(p\left(X\right)\right)\geq\mathbb{E}_{z\sim Q\left(z|X\right)}\left[\log\left(P\left(X|z\right)\right)\right]-KL\left(Q\left(z|X\right)||P\left(z\right)\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
In the equality above, why can we assume that maximizing the right side
 will maximize the likelihood of 
\begin_inset Formula $x$
\end_inset

?
\end_layout

\begin_layout Standard
Some claim about 
\begin_inset Quotes eld
\end_inset

if you have a neural net with high enough capacity we will have 
\begin_inset Formula $KL\left(Q\left(z|X\right)||P\left(z|X\right)\right)=0$
\end_inset

 and we then optimize the likelihood of 
\begin_inset Formula $x$
\end_inset


\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
What are the paramaters of 
\begin_inset Formula $Q\left(z|X\right)$
\end_inset

?
\end_layout

\begin_layout Standard
The paramaters of a neural network which computes two functions: 
\begin_inset Formula 
\[
\left(\mu\left(X,\omega\right),\Sigma\left(X,\omega\right)\right)
\]

\end_inset

 
\begin_inset Formula $\Sigma$
\end_inset

 is constrained to be diagonal.
\end_layout

\begin_layout Subsubsection*
What is the closed form solution of 
\begin_inset Formula $KL\left(Q\left(z|X\right)||P\left(z\right)\right)$
\end_inset

?
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{2}\left(\text{trace}\left(\Sigma\left(x\right)\right)+\|\mu\|^{2}-k-\det\left(\Sigma\left(x\right)\right)\right)
\]

\end_inset

This is derivable.
\end_layout

\begin_layout Subsubsection*
Describe the feedforward phase for VAEs:
\end_layout

\begin_layout Standard
Feedforward:
\end_layout

\begin_layout Enumerate
Sample some 
\begin_inset Formula $X$
\end_inset


\end_layout

\begin_layout Enumerate
Run the encoder 
\begin_inset Formula $Q\left(z|X\right)$
\end_inset

 in order to obtain 
\begin_inset Formula $\mu\left(X\right),\Sigma\left(X\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Sample 
\begin_inset Formula $z$
\end_inset

 using the reparamatization trick: sample 
\begin_inset Formula $\epsilon\sim\mathcal{N}\left(0,I\right)$
\end_inset

, then compute 
\begin_inset Formula $z=\mu\left(X\right)+\Sigma^{\frac{1}{2}}\left(X\right)\cdot\epsilon$
\end_inset

.
 This 
\begin_inset Formula $z$
\end_inset

 distributes: 
\begin_inset Formula $\mathcal{N}\left(\mu\left(X\right),\Sigma\left(X\right)\right)$
\end_inset

.
\end_layout

\begin_layout Enumerate
Run the encoder on 
\begin_inset Formula $z$
\end_inset

 generating 
\begin_inset Formula $f\left(z\right)$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Write down the PDF of a multivariate normal function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left(2\pi\right)^{\frac{-k}{2}}\det\left(\Sigma\right)^{-\frac{1}{2}}e^{-\frac{1}{2}\left(x-\mu\right)^{T}\Sigma^{-1}\left(x-\mu\right)}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Describe the Backpropogation procedure in VAEs:
\end_layout

\begin_layout Standard
After the feedforward we backprop in order to maximize:
\begin_inset Formula 
\[
\log\left(P\left(X|z\right)\right)-KL\left(Q\left(z|X\right)||P\left(z\right)\right)
\]

\end_inset

We optimize both the encoder and decoder on both losses.
 We have a closed form solution for the 
\begin_inset Formula $KL$
\end_inset

 divergence.
 
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

The log likelihood can be computed as such:
\begin_inset Formula 
\begin{align*}
\log\left(P\left(X|z\right)\right) & =\log\left(\left(2\pi\right)^{\frac{-k}{2}}\det\left(\sigma^{2}I\right)^{-\frac{1}{2}}e^{-\frac{1}{2}\left(x-f\left(z\right)\right)^{T}\left(\sigma^{2}I\right)^{-1}\left(x-f\left(z\right)\right)}\right)\\
 & =\log\left(\left(2\pi\right)^{\frac{-k}{2}}\det\left(\sigma^{2}I\right)^{-\frac{1}{2}}\right)+\log\left(e^{-\frac{1}{2}\left(x-f\left(z\right)\right)^{T}\left(\sigma^{2}I\right)^{-1}\left(x-f\left(z\right)\right)}\right)\\
 & =C-\frac{1}{2\sigma}\left(x-f\left(z\right)\right)^{T}\left(x-f\left(z\right)\right)\\
 & =C-O\left(\|x-f\left(z\right)\|_{2}^{2}\right)
\end{align*}

\end_inset

 This is maximized when 
\begin_inset Formula $\|x-f\left(z\right)\|_{2}^{2}$
\end_inset

 is minimized, so we simply backprop from this norm.
\end_layout

\end_body
\end_document
